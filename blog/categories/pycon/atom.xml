<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Pycon | lvh]]></title>
  <link href="http://www.lvh.io/blog/categories/pycon/atom.xml" rel="self"/>
  <link href="http://www.lvh.io/"/>
  <updated>2014-05-29T13:46:09+02:00</updated>
  <id>http://www.lvh.io/</id>
  <author>
    <name><![CDATA[lvh]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[More on Financial Aid Grant Optimization]]></title>
    <link href="http://www.lvh.io/blog/2014/04/06/more-on-financial-aid-grant-optimization/"/>
    <updated>2014-04-06T20:34:27+02:00</updated>
    <id>http://www.lvh.io/blog/2014/04/06/more-on-financial-aid-grant-optimization</id>
    <content type="html"><![CDATA[
<p>In <a href="http://www.lvh.io/blog/2014/03/10/optimization-problems-and-pycon-financial-aid/">a previous post</a>, I talked about ways to optimize PyCon financial aid grants. This is a follow-up on those efforts. Quick recap:</p>

<ul>
<li>There is a fixed budget $b$ available for grants, between 100k and 200k USD.</li>

<li>There are a number of people (approximately 300) requesting various amounts $r_i$ (approximately between 100 USD and 2000 USD) of financial aid, and receive a grant $g_i$ so that $0 \le g_i \le r_i$.</li>

<li>Financial aid applicants can be assigned scores $s_i$, a relative value describing how much we’d like to have them at PyCon.</li>

<li>PyCon wants to optimize the total expected value of scores. That means getting as many people as possible to come, weighted by score.</li>

<li>We’ve conjectured that we can estimate the probability $p_i$ that someone attends as either $g_i/r_i$, or $(g_i/r_i)^2$. The former prefers to spread the budget across a larger number of smaller grants, whereas the latter prefers to focus the budget into a smaller number of larger grants.</li>
</ul>

<p>If any of that doesn’t make sense, you should read <a href="http://www.lvh.io/blog/2014/03/10/optimization-problems-and-pycon-financial-aid/">the previous blog post</a> for more details.</p>

<p>In short, we’re trying to solve the optimization problem:</p>

<p>$$\max \sum E[S_i] = \sum s_i \cdot p_i$$</p>

<p>Since most optimization texts appear to prefer minimization, alternatively:</p>

<p>$$\min - \sum s_i \cdot p_i$$</p>

<p>Subject to a budget constraint and an individual grant constraint:</p>

<p>$$\sum g_i \le b$$</p>

<p>$$0 \le g_i \le r_i$$</p>

<p>The greater-than-zero constraint for individual grants is fairly important, otherwise the algorithm might casually give you answers like:</p>

<p>“ = 1: [10. 20. -20. 30. 50. 10. 50.], sum: 150.0</p>

<p>“</p>

<p>That list in the middle are the per-person grants. Notice how the algorithm feels that the third person really ought to pony up some cash so that some of the other people can go to PyCon ;-)</p>

<h2 id="squared_problems">Squared problems</h2>

<p>In the <a href="http://www.lvh.io/blog/2014/03/10/optimization-problems-and-pycon-financial-aid/">previous blog post</a> I ran into issues using a very generic constraint solver. I ended that post saying that I would try to remeedy that by applying a more specific solver that takes advantage of a particular structure of the problem.</p>

<p>When you set $p_i = g_i/r_i$, this turns into a linear programming problem, since $r_i$ is a constant. When you set $p_i = \left(g_i/r_i\right)^2$, it turns into a quadratic programming problem. Turns out there’s two things I missed about the quadratic problem:</p>

<ul>
<li>The resulting problem is not convex. That means it’s (probably) difficult to solve.</li>

<li>The estimated probability that someone will attend falls off sharply as soon as they don’t receive the full amount they requested. At 50% of the requested grant, the estimated probability of attending is only 25%; at 90%, it’s 81%. This is the opposite of what we want.</li>
</ul>

<h2 id="fixing_the_model">Fixing the model</h2>

<p>That doesn’t mean we should put the $(g_i/r_i)^k$ out to pasture: it just means that I didn’t pick the $k$ I really wanted. Specifically, if I were to pick $k=1/2$, I’d get:</p>

<p>$$p_i = \left(\frac{g_i}{r_i}\right)^{1/2} = \sqrt{\frac{g_i}{r_i}}$$</p>

<p>In general, if $k = 1/n$:</p>

<p>$$p_i = \left(\frac{g_i}{r_i}\right)^{1/n} = \sqrt[n]{\frac{g_i}{r_i}}$$</p>

<p>That problem <em>is</em> convex, but it isn’t linear, quadratic, or some other easy specific problem. It’s just constrained multivariate convex optimization. That’s okay, there are still a couple of applicable optimization algorithms.</p>

<p>Some of these algorithms require the derivative of the goal function with respect to a particular grant size $g_j$ at a particular point. In case we don’t have the real derivative, we can still provide a numerical approximation. In our case, we don’t really need to approximate, since the derivatives are fairly easy to compute analytically:</p>

<p>$$\frac{\partial}{\partial g_j} \sum_i s_i \cdot \sqrt[n]{\frac{g_i}{r_i}} = \frac{s_j \cdot {g_j}^{\frac{1}{n} - 1}}{\sqrt[n]{r_j} \cdot n}$$</p>

<h2 id="finding_a_solution_with_python">Finding a solution with Python</h2>

<p>There are a few Python packages that contain optimization algorithms:</p>

<ul>
<li>SciPy</li>

<li>cvxopt</li>

<li>pyopt</li>
</ul>

<p>Someone originally pointed me towards cvxopt. While I’m sure it’s excellent software, I already knew SciPy, so I went with that.</p>

<p>SciPy’s optimization module provides the following algorithms:</p>

<ul>
<li><code>fmin_l_bfgs_b</code> - Zhu, Byrd, and Nocedal’s constrained optimizer</li>

<li><code>fmin_tnc</code> - Truncated Newton code</li>

<li><code>fmin_cobyla</code> - Constrained optimization by linear approximation</li>

<li><code>fmin_slsqp</code> - Minimization using sequential least-squares programming</li>

<li><code>nnls</code> - Linear least-squares problem with non-negativity constraint</li>
</ul>

<p>The first two are not applicable because they only appear to support bounds on individual variables. I also need a constraint over the <em>sum</em> of variables for the budget: $\sum g_i \le b$. The last one isn’t applicable because this isn’t a linear least-squares problem. That leaves <code>cobyla</code> and <code>slsqp</code>.</p>

<h2 id="experimenting_with_linear_approximation_cobyla">Experimenting with linear approximation (COBYLA)</h2>

<p>Making COBYLA work ended up being pretty easy. The only non-trivial part is expressing all your constraints as expressions greater than or equal to zero.</p>

<p>I’ve uploaded my IPython notebook (<a href="http://nbviewer.ipython.org/gist/lvh/10107818">viewer</a>, <a href="https://gist.github.com/lvh/10107818">gist</a>).</p>

<p>This produced the following results:</p>

<p>“cores: [1 1 1 2 3 5 5] requested: [10 20 30 30 50 10 50] total: 200, budget: 150 k = 1/0.5: [10. 20. 30. 30. 50. 10. 0.], sum: 150.0 k = 1/1: [10. -0. 0. 30. 50. 10. 50.], sum: 150.0 k = 1/2: [10. 10. 7. 27. 36. 10. 50.], sum: 150.0 k = 1/3: [10. 11. 9. 25. 35. 10. 50.], sum: 150.0 k = 1/5: [10. 11. 10. 24. 35. 10. 50.], sum: 150.0 k = 1/10: [10. 11. 11. 23. 35. 10. 50.], sum: 150.0 k = 1/100: [10. 11. 11. 23. 34. 10. 50.], sum: 150.0</p>

<p>“</p>

<p>Some takeaways:</p>

<ul>
<li>As predicted, as $1/k$ increases, the optimization gradually starts spreading the budget out more evenly; preferring to give many partial grants rather than a few large ones.</li>

<li>This effect is mostly only pronounced for $1/k = 2, 3$; after that, increasing $1/k$ doesn’t make much of a difference anymore. This is what I’d expect when I visualize the $p_i$ functions in my head, but I haven’t ruled out numerical instability.</li>

<li>Even at high $1/k$, the two high scorers get their full grant amount. That’s quite understandable for the one that’s only asking for 10, but even the one asking for a large grant gets it unconditionally. This probably means that tweaking the scoring functions is going to be very important.</li>

<li>The linear version is apparently already quite brutal: the person with score 3 requesting 50 simply gets it entirely, leaving no budget left over for the people with score 1.</li>
</ul>

<p>Since I’m so pleased with these results, I’m skipping <code>slsqp</code> until I feel like it. Next up, I’ll try to compare the COBYLA results above with the results of the greedy algorithm under various fitness metrics.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Optimal Hotel Room Pairing]]></title>
    <link href="http://www.lvh.io/blog/2014/03/18/optimal-hotel-room-pairing/"/>
    <updated>2014-03-18T13:05:52+01:00</updated>
    <id>http://www.lvh.io/blog/2014/03/18/optimal-hotel-room-pairing</id>
    <content type="html"><![CDATA[
<p>The greedy hotel pairing algorithm from my <a href="http://blog.lvh.io/blog/2014/03/10/optimization-problems-and-pycon-financial-aid/">previous post</a> gives good solutions. If you make some fairly reasonable-sounding assumptions about the problem, <em>very</em> good solutions. At any rate nicer than forcing a human to drudge through it; both in terms of person-hours spent and quality of the solutions.</p>

<p>However, it turns out I was wrong about them being <em>optimal</em> solutions. There’s no guarantee they would be, and in fact a good chance that they won’t.</p>

<h2 id="finding_optimal_solutions">Finding optimal solutions</h2>

<p>The good news is that there is a way to find the optimal solution. This problem can be modeled as a <a href="https://en.wikipedia.org/wiki/Matching_%28graph_theory%29">graph matching problem</a>; what we’re trying to find is a weighted maximal matching.</p>

<p>This is really easy if the graph is bipartite, but in our case we’re actually dealing with two <a href="https://en.wikipedia.org/wiki/Complete_graph">complete graphs</a>: we try to pair people with similar gender. Within that compatible group, anyone can theoretically pair with anyone.</p>

<p><img src='https://upload.wikimedia.org/wikipedia/commons/8/86/10-simplex_graph.svg' /></p>

<p>People interested in additional reading might be interested in:</p>

<ul>
<li><a href="http://theory.stanford.edu/~jvondrak/CS369P-files/lec6.pdf">Notes from a Stanford course by Jan Vondrak</a></li>

<li><a href="http://www-sop.inria.fr/members/Frederic.Havet/Cours/matching.pdf">Notes from an Inria course by Frederic Havet</a></li>
</ul>

<h2 id="picking_an_algorithm">Picking an algorithm</h2>

<p>There are several feasible algorithms for this.</p>

<ul>
<li><a href="https://en.wikipedia.org/wiki/Blossom_algorithm">Edmonds’ blossom algorithm</a>, the first polynomial-time algorithm with running time $O(V^4)$ or $O(V^2\cdot E)$</li>

<li>Gabow’s 1973 PhD thesis, an $O(V^3)$ algorithm</li>

<li><a href="http://dl.acm.org/citation.cfm?id=1382663">An $O(\sqrt{V} \cdot E)$ improvement</a> by Micali (yes, <a href="https://en.wikipedia.org/wiki/Silvio_Micali"><em>that</em> Micali</a>) and Vazirani</li>

<li>Another improvement by Gabow, $O(V(E + \log{V}))$</li>
</ul>

<p>The current state of the art in computerized algorithms appears to be <a href="http://pub.ist.ac.at/~vnk/papers/blossom5.pdf">Blossom V</a> by Vladimir Kolmogorov. This algorithm finds <em>perfect</em> matchings (i.e. all nodes are included), which may be impossible for us, e.g. because of an odd number of pairs.</p>

<h2 id="issues">Issues</h2>

<p>One issue with this approach is that it becomes pretty much impossible to adapt this to rooms for more than two people. In order to support that case my previous greedy algorithm remains the best thing I’ve found.</p>

<p>I was unable to find an implementation of this in Java or Clojure. Fortunately, there is a Python library called <a href="http://networkx.lanl.gov">NetworkX</a> that does have <a href="http://networkx.lanl.gov/reference/generated/networkx.algorithms.matching.max_weight_matching.html">an implementation</a>.</p>

<p>I have not yet turned this into a fully functional program, because:</p>

<ul>
<li>it’s too late to apply it for this year</li>

<li>there’s a good chance we won’t be doing this again for next year</li>
</ul>

<h2 id="credits">Credits</h2>

<p>I’d like to thank Tor Myklebust (<code>tmyklebu</code> on Freenode) for pointing out I was wrong, and shoving me in the direction of the answers.</p>

<p>In this blog post I used several freely available graph illustrations from Wikipedia. The complete graph illustrations were made by <a href="https://commons.wikimedia.org/wiki/User:Koko90">koko90</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Optimization Problems and PyCon Financial Aid]]></title>
    <link href="http://www.lvh.io/blog/2014/03/10/optimization-problems-and-pycon-financial-aid/"/>
    <updated>2014-03-10T16:47:00+01:00</updated>
    <id>http://www.lvh.io/blog/2014/03/10/optimization-problems-and-pycon-financial-aid</id>
    <content type="html"><![CDATA[
<p>This year, I have partly taken on some new responsibilities in organizing PyCon. Specifically, I’ve done some work on financial aid. (Next year, I will be taking on the position of financial aid chair.) There have been some challenges that I’ve thrown some code at. Some of it stuck.</p>

<p>I’m very much interested in your comments, thoughts, alternative approaches, et cetera. Hit me up on <a href="https://twitter.com/lvh">Twitter</a>.</p>

<h2 id="hotel_room_allocation">Hotel room allocation</h2>

<p>The first issue I solved was one of hotel room allocation. We provide the financial aid applicants with hotel rooms. To keep costs down, we pair people up, two by two.</p>

<p>We want to pair people so that we have to book a minimal number of days. If there’s days on the start of the room booking where only one person is booking the room, we have to pay for the rest.</p>

<h3 id="a_greedy_algorithm">A greedy algorithm</h3>

<p>I start out with generating every possible pairing. Assuming we have 300 financial aid applicants, that’s:</p>

<p>$${300 \choose 2} = \frac{300!}{2! \cdot 298!} = 44850$$</p>

<p>That’s more than we can check by hand, but still pretty easy for a computer. Besides, there are actually fewer pairs than that: some people request to be paired together explicitly, and we only pair people of the same gender.</p>

<p>Then, I sort them by number of unmatched days, that is, how many days would have a single person in the hotel room if we paired them together. Finally, I just greedily start grabbing pairs, keeping track of the people that have been allocated rooms as I go along. As soon as everyone is accounted for, we stop.</p>

<p>Other than perhaps minding the edge conditions where you have an odd number of people to pair, this isn’t too tricky. The implementation for this is on Github, in <a href="https://github.com/lvh/pairing/blob/master/src/pairing/core.clj"><code>lvh/pairing</code></a>.</p>

<h3 id="solution_meet_reality">Solution, meet reality</h3>

<p>Before I wrote this, humans did this by hand. That took pretty long, and the solutions were decent, but suboptimal. All the humans that have tackled this problem seem to take the same approach: sort by check-in date, find exact or near matches in check-out dates, rinse, repeat.</p>

<p>The algorithm above did quite well, coming up with a significantly better result than the previous human allocation. It also produced very <em>interesting</em> solutions. Turns out that by taking a big hit on one of the pairs (say, a pair that’s 4 days mismatched four days), you can limit the damage on a large number of other pairs, and still come out on top. After reviewing with the person who previously had to do this manually, we quickly agreed that a human would most likely not have come up with this.</p>

<p>Furthermore, a lot of the pairs have matching check-out dates but with a mismatched check-in date; whereas humans typically only look for solutions in the other direction. This is easy to explain in hindsight; the algorithm has no concept of an ordering of events in time. It just tries to minimize the number of mismatched days.</p>

<p>I’m quite happy with the result. Any dollar I’m not devoting to a room that isn’t being fully used will instead be going into an increased grant.</p>

<p>Unfortunately, finding this solution isn’t the end of the story. It rarely survives the clash with reality. Many complex factors affect it: people will drastically change their room dates, people’s visas get denied, et cetera. All sorts of unforseeable circumstances have lead to changes to the answer the algorithm originally produced. I don’t expect that to change until PyCon is over; unfortunately, I also don’t think that’s a problem I can fix in a few lines of Clojure.</p>

<h2 id="grant_allocation">Grant allocation</h2>

<p>The second issue is a much thornier one. Given the financial aid budget, figure out how to optimally distribute it. The budget is quite limited, a good deal smaller than the sum of what everyone requests.</p>

<p>There’s a few reasons why this problem is complex. First of all, “optimal” is highly subjective. As I’m sure you’ll notice very soon after thinking about it, it’s very easy to verge off from math and straight into the realm of politics.</p>

<h3 id="a_very_simple_greedy_algorithm">A very simple greedy algorithm</h3>

<p>You might say that you want to get as many people as possible to come to PyCon, and you just greedily allocate the smallest grant requests first. This has a few disadvantages:</p>

<ol>
<li>It biases against the people that ostensibly need the money the most.</li>

<li>It is ordering-sensitive: equivalent applications that happen to come later in the queue are disadvantaged.</li>

<li>It oversimplifies how people react to grants, by making grant allocation binary. Someone receiving 90% of their requested grant amount will likely still be able to attend. Suppose you have 11 people, all requesting 100 USD, and you have 1000 USD to spend. The greedy algorithm would give the first ten of them 100 USD and find its purse empty for the eleventh. It would almost certainly be better to give them all 90.91 USD instead.</li>

<li>Game-theoretically, it makes a lot of sense for everyone to apply for a small grant that they will almost certainly get. (This is not a real issue for us, because we still have humans eyeballing all the applications.)</li>

<li>The only difference between applications is the amount they’re requesting, but there are people that we would like to bias in favor of. For example, we’d like to try very hard to get speakers or tutorial presenters to the conference, we might want to reward people doing open source work, et cetera.</li>
</ol>

<p>Selecting these critera is definitely squarely in the realm of politics, and I’d like to stick to the realm of math; so let’s just assume that we can assign scores to applicants and that those scores are fair and just. If you feel like we shouldn’t bias in favor of anyone at all, just assume that whenever I say “the score of an applicant” I mean “the number 1”.</p>

<h3 id="a_slightly_smarter_greedy_algorithm">A slightly smarter greedy algorithm</h3>

<p>One of the key ideas (which a lot of people seem to have when tackling this problem) is to translate an application’s score into an amount of the budget. So, for example, let’s say that the sum of all scores is 100, and your score is 10, that means you can have up to 10% of the budget allocated to you.</p>

<p>So, I make a pass over all the remaining applicants. If you’re asking less than your budget slice, you get your requested grant. If you’re asking for more, I save you for a future pass. Even though the budget goes down between passes, budget slices will go up, because the total score drops.</p>

<p>You can’t do this in one pass, increasing the budget as you go along if people request less than their slice, because you might introduce order dependence. For example, consider what happens when Alice and Charlie both need more than the budget allows for (and they have the same score and requested amount), and Bob needs less. If you process them in the order Alice - Bob - Charlie, Charlie may get his requested grant and Alice may not, just because Bob’s in the middle making the budget bigger for Charlie.</p>

<p>Once everyone left is requesting more than their slice, they just get their slice instead of their requested amount.</p>

<p>This solution is adequate, but I’m not completely satisfied; everyone besides the last pass will get full grant amounts. You can find my implementation of this algorithm <a href="https://github.com/lvh/hood/blob/master/src/hood/greedy.clj">on Github</a> as well.</p>

<h3 id="a_better_model">A better model</h3>

<p>I think we can do better by applying some elementary probability theory. What we really want is to maximize the total score of the applicants that we expect to see at PyCon as a consequence of financial aid. Probability theory has a thing called the expected value of a random variable, which is pretty much just the integral of the random variable with respect to the probability. In our case, that just means that we want to maximize the sum of the probabiliies that a given applicant will come to PyCon given a particular grant amount, weighted by their score:</p>

<p>$$\max \sum s_i \cdot p_i$$</p>

<p>That just restates problems we can’t solve in terms of problems we can’t solve. What on earth could the probability that someone shows up be? We can’t know the real value, since it’s specific to each individual, and dependent on a lot of random, unknowable events. We can, however, make an educated guess. If we don’t give them any money, they probably won’t come. If we give them the amount they’re asking for, they probably will.</p>

<p>We could conjecture that the probability someone will come to the conference is approximately the fraction of the amount they requested that they actually received:</p>

<p>$$p_i = \frac{g_i}{r_i}$$</p>

<p>For example, if someone gets 90% of their requested grant, we estimate that the odds they will attend are also 90%; if we give them only 10%, we estimate it at just 10%.</p>

<p>Alternatively, we could conjecture that it’s closer to the <em>square</em> of that ratio; when giving someone a value that’s very close to what they asked for, their probability of attending is still going to be very high; but if we only give them half, the odds they will attend will be closer to 25%, much lower than 50%. So, the expression becomes:</p>

<p>$$p^{\prime}_i = \left(\frac{g_i}{r_i}\right)^{2}$$</p>

<p><em>Update:</em> I now realize that this is probably not the expression that I actually want: it falls off very quickly as soon as an applicant gets anything less than the full amount. I’ve elaborated on this in <a href="http://www.lvh.io/blog/2014/04/06/more-on-financial-aid-grant-optimization/">a new blog post</a>.</p>

<p>We will see how the square model emphasizes focusing the available funds on fewer grants, whereas the linear model will spread smaller grants more liberally.</p>

<h3 id="an_attempt_with_constraint_solvers">An attempt with constraint solvers</h3>

<p>(I would like to thank Mark Engelberg for helping me with the stuff in this chapter. It may not have panned out, but it was a very educational experience nonetheless.)</p>

<p>It’d be nice if we could just declaratively describe the problem, throw it into a computer program, and have it magically tell us the answer. Of course, there are programs that do exactly that, called solvers.</p>

<p>When I reached out on the Clojure mailing list, Mark Engelberg helpfully reached out and immediately handed out some cool runnable example for me to play with. Sure enough, they worked super, and with a carefully crafted three-person example we could clearly see the difference between the linear and quadratic models I was talking about above: under the square model, the concentrated grants, trying harder to give high-scoring applications the amount they requested. The linear model spread money out more evenly. That is, with the following applications:</p>

<p>“ojure (def alice ) (def bob ) (def carol )</p>

<p>“</p>

<p>In a linear model, it comes up with:</p>

<p>“ojure {alice 120 bob 80 carol 0}</p>

<p>“</p>

<p>However, in the quadratic model, the optimizer rather gives Carol (who has a lower score) a complete grant than give Bob a partial one:</p>

<p>“ojure {alice 120 bob 0 carol 80}</p>

<p>“</p>

<p>You can find the code <a href="https://github.com/lvh/hood/blob/master/src/hood/constraint.clj">on Github</a>. The tests that confirm the difference in behavior for the linear and quadratic models are in <a href="https://github.com/lvh/hood/blob/master/test/hood/constraint_test.clj">the tests</a>.</p>

<p>There’s one issue though; it didn’t scale. Not bad enough that you’d notice on the three-person example (I thought my REPL was just being laggy), but bad enough that any real-world problem would be completely unsolvable. Why? Clearly constraint solvers are awesome real world tools with real world usage, it’s not like they’re supposed to fall over as soon as you throw a problem of reasonable size at it.</p>

<p>Well, let’s do some napkin math. If we have 200 financial aid recipients that are all getting 1000 possible options (somewhere between 0 USD and 1000 USD, in whole-dollar increments), there’s 200,000 possible places to put any given dollar. If we have 100,000 USD to spend, that’s:</p>

<p>$${2 \cdot 10^{5} \choose 10^{5}} = \frac{(2 \cdot 10^{5})!}{10^{5}! \cdot 10^{5}!} \approx 10^{60203}$$</p>

<p>That is a very big number. I needed logarithms to compute it. It is so huge that it makes the number of atoms in the observable universe (about $10^{80}$) look like rounding error.</p>

<p>In an attempt to “fix” that problem, I tried only handing out funds in chunks of 100 USD each. Then, we have 1000 chunks to hand out and 2000 places to put them:</p>

<p>$${2000 \choose 1000} = \frac{2000!}{1000! \cdot 1000!} \approx 10^{600}$$</p>

<p>I have made the problem 59,603 decimal orders of magnitude easier! Rejoice!</p>

<p>A constraint solver really doesn’t “know” anything about the structure of the problem you’re feeding it. That’s a trade-off: in return, it grants you a lot of freedom in expressing your problem. Constraint solvers like LoCo are very valuable, they just aren’t a good fit for this problem. They are designed for problems where the constraints really constraining the solution space. We’re clearly not in that territory. We have many valid solutions, and we’re struggling to look for a <em>good</em> one.</p>

<p>There are two ways we can fix this:</p>

<ol>
<li>Compromising on the freedom of expressing the problem. By pouring our problem into a specific structured shape, we may be able to use a much faster solver, specific to that class of problems. Also, by allowing arbitrary real numbers instead of just integers, we can use much faster solvers.</li>

<li>Compromising on finding the <em>optimal</em> solution, instead searching for a <em>decent</em> solution. You can do that with algorithms like tabu search or simulated annealing.</li>
</ol>

<p>I will be elaborating on these problems in a future blog post.</p>
]]></content>
  </entry>
  
</feed>
