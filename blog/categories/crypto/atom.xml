<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Crypto | lvh]]></title>
  <link href="http://lvh.github.com/blog/categories/crypto/atom.xml" rel="self"/>
  <link href="http://lvh.github.com/"/>
  <updated>2014-04-05T23:23:13+02:00</updated>
  <id>http://lvh.github.com/</id>
  <author>
    <name><![CDATA[Laurens Van Houtven]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Thoughts on RDRAND in Linux]]></title>
    <link href="http://lvh.github.com/blog/2013/10/19/thoughts-on-rdrand-in-linux/"/>
    <updated>2013-10-19T21:47:00+02:00</updated>
    <id>http://lvh.github.com/blog/2013/10/19/thoughts-on-rdrand-in-linux</id>
    <content type="html"><![CDATA[
<p>This has been brewing since I read <a href="https://www.change.org/en-GB/petitions/linus-torvalds-remove-rdrand-from-dev-random-4/responses/9066">Linus’ response to the petition to remove <code>RDRAND</code> from /dev/random</a>.</p>

<p>For those of you who don’t know, <code>RDRAND</code> is a CPU instruction introduced by Intel on recent CPUs. It (supposedly) uses a hardware entropy source, and runs it through AES in CBC-MAC mode, to produce random numbers.</p>

<p>Out of fear that <code>RDRAND</code> may somehow be backdoored, someone petitioned to remove <code>RDRAND</code> support to “improve the overall security of the kernel”. If <code>RDRAND</code> contains a back door, and an unknown attacker can control the output, that could break pretty much all userland crypto.</p>

<p>Linus fulminated, as he is wont to do. He suggested we go read <code>drivers/char/random.c</code>. I quote (expletives and insults omitted):</p>

<p>&gt; we use rdrand as <em>one</em> of many inputs into the random pool, and we &gt; use it as a way to <em>improve</em> that random pool. So even if rdrand &gt; were to be back-doored by the NSA, our use of rdrand actually &gt; improves the quality of the random numbers you get from &gt; /dev/random.</p>

<p>I went ahead and read <code>random.c</code>. You can read it for yourself <a href="https://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/tree/drivers/char/random.c">in Linus’ tree</a>.</p>

<p>Disclaimer: I am not an expert in this piece of code. I have no doubt Linus is far more familiar with it than I am. I’d love to be proven wrong. I’m just taking his advice and reading some code.</p>

<p>The function I’m interested in is <code>extract_buf</code>:</p>

<p>“`c</p>

<pre><code>/*
 * If we have a architectural hardware random number
 * generator, mix that in, too.
 */
for (i = 0; i &lt; LONGS(EXTRACT_SIZE); i++) {
	unsigned long v;
	if (!arch_get_random_long(&amp;v))
		break;
	hash.l[i] ^= v;
}</code></pre>

<p>“`</p>

<p>This is in the extraction phase. This is after the hash is being mixed back in to the pool (and that’s for backtracking attacks: not intended as an input to the pool). It seems to me like the output of <code>arch_get_random_long</code> is being XORed in with the extracted output, not with the pool.</p>

<p>If I were to put on my tin-foil hat, I would suggest that the difficulty has now been moved from being able to subvert the pool as one of its entropy sources (which we think is impossible), versus being able to see what you’re about to be XORed with. The latter seems a lot closer to the realm of stuff a microcode instruction can do.</p>

<p>To put it into Python:</p>

<p>“`python from inspect import currentframe from random import getrandbits</p>

<p>def extract_buf(): ””“Gets 16 bytes from the pool, and mixes them with RDRAND output.</p>

<pre><code>&quot;&quot;&quot;
pool_bits = extract_from_pool()
rdrand_bits = rdrand()
return  pool_bits ^ rdrand_bits</code></pre>

<p>def extract_from_pool(): ””“Pretend to get some good, unpredictable bytes from the pool.</p>

<pre><code>Actually gets a long with some non-cryptographically secure random
bits from random.getrandbits, which is usually a Mersenne Twister.

&quot;&quot;&quot;
return getrandbits(32)</code></pre>

<p>def rdrand(): ””” A malicious hardware instruction. ””” pool_bits = currentframe().f_back.f_locals[pool_bits] return pool_bits ^ 0xabad1dea</p>

<p>if <strong>name</strong> == “__main__”: assert extract_buf() == 0xabad1dea</p>

<p>“`</p>

<p>Why can’t RDRAND work like this?</p>

<p>Some comments based on feedback I’ve gotten so far:</p>

<ol>
<li>This attack does not need to know where the PRNG state lives in memory. First of all, this isn’t an attack on the PRNG state, it’s on the PRNG output. Secondly, the instruction only needs to peek ahead at what is about to happen (specifically, what’s about to be XORed with) the RDRAND output. That doesn’t require knowing where the PRNG state (or its output) is being stored in memory; we’re already talking register level at that point.</li>

<li>While it’s certainly true that if you can’t trust the CPU, you can’t trust anything, that doesn’t really make this problem go away. <code>RDRAND</code> being broken wouldn’t make software crash, which is a lot harder for almost all other instructions. <code>RDRAND</code> being broken wouldn’t result in measurable side-effects, unlike what would happen if <code>PCLMULDQ</code> contained a back door. Furthermore, it’s a lot easier to backdoor one single microcode instruction and a lot more plausible and feasible for a CSPRNG to be backdoored than it is to think of a CPU as some kind of intelligent being that’s actively malicious or being remotely controlled.</li>
</ol>

<p>For what it’s worth, it seems <a href="https://twitter.com/zooko/status/392334674690723840">Zooko agrees with me</a>.</p>
]]></content>
  </entry>
  
</feed>
