<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Crypto | lvh]]></title>
  <link href="http://www.lvh.io/blog/categories/crypto/atom.xml" rel="self"/>
  <link href="http://www.lvh.io/"/>
  <updated>2014-05-29T13:46:09+02:00</updated>
  <id>http://www.lvh.io/</id>
  <author>
    <name><![CDATA[lvh]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[On TrueCrypt and Full-disk Encryption]]></title>
    <link href="http://www.lvh.io/blog/2014/05/29/on-truecrypt-and-full-disk-encryption/"/>
    <updated>2014-05-29T10:53:30+02:00</updated>
    <id>http://www.lvh.io/blog/2014/05/29/on-truecrypt-and-full-disk-encryption</id>
    <content type="html"><![CDATA[
<p>Since the early hours of May 29th (CEST), <a href="https://www.truecrypt.org">the TrueCrypt website (<code>https://www.truecrypt.org</code>)</a> has pointed to <code>http://truecrypt.sourceforge.net/</code>, with an ominous-looking error message:</p>

<blockquote>
<p>WARNING: Using TrueCrypt is not secure as it may contain unfixed security issues</p>

<p>This page exists only to help migrate existing data encrypted by TrueCrypt.</p>

<p>The development of TrueCrypt was ended in 5/2014 after Microsoft terminated support of Windows XP. Windows 8/7/Vista and later offer integrated support for encrypted disks and virtual disk images. Such integrated support is also available on other platforms (click here for more information). You should migrate any data encrypted by TrueCrypt to encrypted disks or virtual disk images supported on your platform.</p>
</blockquote>

<p>The website then explains how you can install BitLocker, a proprietary disk encryption system available in many versions of Windows, as well as how you could “rescue” existing TrueCrypt volumes.</p>

<p>People were pretty unhappy, for a variety of reasons:</p>

<ul>
<li>Lack of trust in proprietary full-disk encryption software.</li>

<li>Many versions of Windows didn’t even ship with BitLocker, only a few “premium” versions did.</li>
</ul>

<p>As a proprietary system, BitLocker is not susceptible to the same amount of public scrutiny as a publicly available system. This is in stark contrast with TrueCrypt, where Matt Green recently raised around 70k USD to perform an <a href="http://istruecryptauditedyet.com/">audit</a>.</p>

<p>There are variety of scenarios that could’ve caused the TrueCypt website to suddenly sport that message. The live Internet audience has speculated wildly. I’ll share my thoughts on that near the end of this post, but there are two points I’d like to make that I think are far more important:</p>

<ol>
<li>Consider if full-disk encryption is really what you want.</li>

<li>If it is, consider if it should be TrueCrypt.</li>
</ol>

<h3 id="fulldisk_encryption">Full-disk encryption</h3>

<p>Something I learned from the inimitable <a href="https://zooko.com">Zooko</a>:</p>

<blockquote>
<p>Security isn’t about perfect versus imperfect or about better versus worse, it’s about <em>this</em> attack surface versus <em>that</em> attack surface.</p>
</blockquote>

<p>You can’t just add more crypto junk to something and expect to somehow get better security. You have to consider what it is buying you, and what it’s costing you.</p>

<p>Full-disk encryption buys you one simple thing: if someone steals your device while the encrypted volume is locked, they probably can’t read it.</p>

<p>If the encrypted volume is unlocked, it’s over; and that’s the state it’s probably usually in. If the key lives in RAM (it usually does), there’s a variety of ways that can be extracted. There’s devices that have complete direct memory access, including everything that speaks FireWire or has FireWire-compatibility built-in. Even if you shut off your machine, cold boot attacks mean that the key can be extracted for a limited about of time. Various jurisdictions can try to force you to hand over the keys.</p>

<p>If an attacker can write to the (encrypted!) volume, it’s probably over. Virtually all sector-level full-disk encryption formats are unauthenticated (with good reason), they’re all malleable and vulnerable to (adaptive) chosen-ciphertext attacks.</p>

<p>If you’re encrypting files or blobs of data within other files, an authenticated encryption scheme like GPG is far more useful.</p>

<p>Don’t get me wrong. Full-disk encryption is a good idea, and you should do it. I’m just saying that what it actually protects against is pretty limited. If there’s files you want to keep secret, full-disk encryption is probably not enough.</p>

<p>For more details, try Thomas &amp; Erin Ptacek’s <a href="http://sockpuppet.org/blog/2014/04/30/you-dont-want-xts/">blog post</a> on why XTS isn’t what you want. XTS is a way to build tweakable ciphers that can be used to create full-disk encryption; but the post applies to full-disk encryption generically as well.</p>

<h3 id="truecrypt_as_a_fulldisk_encryption_mechanism">TrueCrypt as a full-disk encryption mechanism</h3>

<p>So, you probably want full-disk encryption, and you probably want to make sure that sensitive data is encrypted on top of that. Great. What full-disk encryption scheme do you use?</p>

<p>I don’t want to bash TrueCrypt. It is (was, perhaps?) a great go-to project for full-disk encryption. It got a lot of things right. It also got a bunch of things wrong.</p>

<p>TrueCrypt was made by a bunch of people we don’t know occasionally throwing a bunch of binaries over the wall. The source is available (under a non-OSI license), so you could audit that and compile your own binaries, but the truth is that the vast majority of TrueCrypt users never actually did that.</p>

<p>The TrueCrypt disk format and encryption standards are a bit iffy. It has terrible file system support. It has major performance issues, partially due to questionable cryptographic practices such as cipher cascades. It was great for when it was originally conceived and full-disk encryption was still new and exciting, it’s still pretty decent now, but we can certainly do better.</p>

<h3 id="what_actually_happened_to_the_website">What actually happened to the website?</h3>

<p>We don’t really know. There’s a couple of guesses.</p>

<p>First of all, it looks like it are the original authors that folded: the key is the same one that was being used to sign releases months ago. Of course, that could mean that it was compromised or that they were forced to hand it over.</p>

<p>Since the DNS records changed, the e-mail server behavior changed, the same key was used, the Sourceforge client was involved, and fairly major changes to the source code were involved, it’s unlikely that it’s a simple defacement.</p>

<p>It’s unlikely that they folded because they felt discovery of some backdoor was imminent. Folding would actually stop that discovery, because the source was already open.</p>

<p>It’s strange that they would point to alternatives like Bitlocker for Windows and even more dubious alternatives for other operating systems. The authors certainly knew that this would not be an acceptable alternative for the vast majority of their users.</p>

<p>Additionally, the support window for XP ending isn’t a particularly convincing impetus for migrating away from TrueCrypt <em>right now</em>. This has lead some to believe that it’s an automated release. Worse, it could be a gagged response: a big and powerful three-letter agency might be twisting their arm and forcing them to fold, in return for something else (like, say, not being thrown in a Gitmo cell and forgotten about). Again: pure speculation.</p>

<p>Another option is that some of the developers just really, genuinely folded. They felt that for atechnical users, BitLocker was good enough, while the particularly discerning TrueCrypt user would be able to find some other alternative.</p>

<p>Bottom line is that none of this really matters. What matters is what you should do next if you want to have full-disk encryption.</p>

<h3 id="so_what_do_i_do_now">So what do I do now?</h3>

<p>I think LUKS is probably the best system that we have right now, and one of the few that actually improves on TrueCrypt.</p>

<p>If you’re on Linux, dm-crypt + cryptsetup + LUKS is probably what you want. If you’re on OS X, FileVault 2 is probably what you want. If you’re on Windows, your options are looking a bit thin right now:</p>

<ul>
<li>Keep using old versions of TrueCrypt.</li>

<li>Give up and use BitLocker.</li>

<li>Use a Linux virtual machine to use dm-crypt/LUKS, eventually migrating to native support.</li>
</ul>

<p>Personally, I think the first option is the most reasonable right now, and then wait until someone actually writes the native LUKS support.</p>

<p>Oh, and you should probably install GPG to encrypt some of those files stored on that encrypted volume.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Thoughts on RDRAND in Linux]]></title>
    <link href="http://www.lvh.io/blog/2013/10/19/thoughts-on-rdrand-in-linux/"/>
    <updated>2013-10-19T21:47:00+02:00</updated>
    <id>http://www.lvh.io/blog/2013/10/19/thoughts-on-rdrand-in-linux</id>
    <content type="html"><![CDATA[
<p>This has been brewing since I read <a href="https://www.change.org/en-GB/petitions/linus-torvalds-remove-rdrand-from-dev-random-4/responses/9066">Linus’ response to the petition to remove <code>RDRAND</code> from /dev/random</a>.</p>

<p>For those of you who don’t know, <code>RDRAND</code> is a CPU instruction introduced by Intel on recent CPUs. It (supposedly) uses a hardware entropy source, and runs it through AES in CBC-MAC mode, to produce random numbers.</p>

<p>Out of fear that <code>RDRAND</code> may somehow be backdoored, someone petitioned to remove <code>RDRAND</code> support to “improve the overall security of the kernel”. If <code>RDRAND</code> contains a back door, and an unknown attacker can control the output, that could break pretty much all userland crypto.</p>

<p>Linus fulminated, as he is wont to do. He suggested we go read <code>drivers/char/random.c</code>. I quote (expletives and insults omitted):</p>

<p>&gt; we use rdrand as <em>one</em> of many inputs into the random pool, and we &gt; use it as a way to <em>improve</em> that random pool. So even if rdrand &gt; were to be back-doored by the NSA, our use of rdrand actually &gt; improves the quality of the random numbers you get from &gt; /dev/random.</p>

<p>I went ahead and read <code>random.c</code>. You can read it for yourself <a href="https://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/tree/drivers/char/random.c">in Linus’ tree</a>.</p>

<p>Disclaimer: I am not an expert in this piece of code. I have no doubt Linus is far more familiar with it than I am. I’d love to be proven wrong. I’m just taking his advice and reading some code.</p>

<p>The function I’m interested in is <code>extract_buf</code>:</p>

<p>“</p>

<pre><code>/*
 * If we have a architectural hardware random number
 * generator, mix that in, too.
 */
for (i = 0; i &lt; LONGS(EXTRACT_SIZE); i++) {
	unsigned long v;
	if (!arch_get_random_long(&amp;v))
		break;
	hash.l[i] ^= v;
}</code></pre>

<p>“</p>

<p>This is in the extraction phase. This is after the hash is being mixed back in to the pool (and that’s for backtracking attacks: not intended as an input to the pool). It seems to me like the output of <code>arch_get_random_long</code> is being XORed in with the extracted output, not with the pool.</p>

<p>If I were to put on my tin-foil hat, I would suggest that the difficulty has now been moved from being able to subvert the pool as one of its entropy sources (which we think is impossible), versus being able to see what you’re about to be XORed with. The latter seems a lot closer to the realm of stuff a microcode instruction can do.</p>

<p>To put it into Python:</p>

<p>“thon from inspect import currentframe from random import getrandbits</p>

<p>def extract_buf(): “”“Gets 16 bytes from the pool, and mixes them with RDRAND output.</p>

<pre><code>&quot;&quot;&quot;
pool_bits = extract_from_pool()
rdrand_bits = rdrand()
return  pool_bits ^ rdrand_bits</code></pre>

<p>def extract_from_pool(): “”“Pretend to get some good, unpredictable bytes from the pool.</p>

<pre><code>Actually gets a long with some non-cryptographically secure random
bits from random.getrandbits, which is usually a Mersenne Twister.

&quot;&quot;&quot;
return getrandbits(32)</code></pre>

<p>def rdrand(): “”“ A malicious hardware instruction. ”“” pool_bits = currentframe().f_back.f_locals[pool_bits] return pool_bits ^ 0xabad1dea</p>

<p>if <strong>name</strong> == “<strong>main</strong>”: assert extract_buf() == 0xabad1dea</p>

<p>“</p>

<p>Why can’t RDRAND work like this?</p>

<p>Some comments based on feedback I’ve gotten so far:</p>

<ol>
<li>This attack does not need to know where the PRNG state lives in memory. First of all, this isn’t an attack on the PRNG state, it’s on the PRNG output. Secondly, the instruction only needs to peek ahead at what is about to happen (specifically, what’s about to be XORed with) the RDRAND output. That doesn’t require knowing where the PRNG state (or its output) is being stored in memory; we’re already talking register level at that point.</li>

<li>While it’s certainly true that if you can’t trust the CPU, you can’t trust anything, that doesn’t really make this problem go away. <code>RDRAND</code> being broken wouldn’t make software crash, which is a lot harder for almost all other instructions. <code>RDRAND</code> being broken wouldn’t result in measurable side-effects, unlike what would happen if <code>PCLMULDQ</code> contained a back door. Furthermore, it’s a lot easier to backdoor one single microcode instruction and a lot more plausible and feasible for a CSPRNG to be backdoored than it is to think of a CPU as some kind of intelligent being that’s actively malicious or being remotely controlled.</li>
</ol>

<p>For what it’s worth, it seems <a href="https://twitter.com/zooko/status/392334674690723840">Zooko agrees with me</a>.</p>
]]></content>
  </entry>
  
</feed>
