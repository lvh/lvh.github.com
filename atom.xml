<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[lvh]]></title>
  <link href="http://www.lvh.io/atom.xml" rel="self"/>
  <link href="http://www.lvh.io/"/>
  <updated>2014-05-29T13:45:01+02:00</updated>
  <id>http://www.lvh.io/</id>
  <author>
    <name><![CDATA[lvh]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[On TrueCrypt and Full-disk Encryption]]></title>
    <link href="http://www.lvh.io/blog/2014/05/29/on-truecrypt-and-full-disk-encryption/"/>
    <updated>2014-05-29T10:53:30+02:00</updated>
    <id>http://www.lvh.io/blog/2014/05/29/on-truecrypt-and-full-disk-encryption</id>
    <content type="html"><![CDATA[
<p>Since the early hours of May 29th (CEST), <a href="https://www.truecrypt.org">the TrueCrypt website (<code>https://www.truecrypt.org</code>)</a> has pointed to <code>http://truecrypt.sourceforge.net/</code>, with an ominous-looking error message:</p>

<blockquote>
<p>WARNING: Using TrueCrypt is not secure as it may contain unfixed security issues</p>

<p>This page exists only to help migrate existing data encrypted by TrueCrypt.</p>

<p>The development of TrueCrypt was ended in 5/2014 after Microsoft terminated support of Windows XP. Windows 8/7/Vista and later offer integrated support for encrypted disks and virtual disk images. Such integrated support is also available on other platforms (click here for more information). You should migrate any data encrypted by TrueCrypt to encrypted disks or virtual disk images supported on your platform.</p>
</blockquote>

<p>The website then explains how you can install BitLocker, a proprietary disk encryption system available in many versions of Windows, as well as how you could “rescue” existing TrueCrypt volumes.</p>

<p>People were pretty unhappy, for a variety of reasons:</p>

<ul>
<li>Lack of trust in proprietary full-disk encryption software.</li>

<li>Many versions of Windows didn’t even ship with BitLocker, only a few “premium” versions did.</li>
</ul>

<p>As a proprietary system, BitLocker is not susceptible to the same amount of public scrutiny as a publicly available system. This is in stark contrast with TrueCrypt, where Matt Green recently raised around 70k USD to perform an <a href="http://istruecryptauditedyet.com/">audit</a>.</p>

<p>There are variety of scenarios that could’ve caused the TrueCypt website to suddenly sport that message. The live Internet audience has speculated wildly. I’ll share my thoughts on that near the end of this post, but there are two points I’d like to make that I think are far more important:</p>

<ol>
<li>Consider if full-disk encryption is really what you want.</li>

<li>If it is, consider if it should be TrueCrypt.</li>
</ol>

<h3 id="fulldisk_encryption">Full-disk encryption</h3>

<p>Something I learned from the inimitable <a href="https://zooko.com">Zooko</a>:</p>

<blockquote>
<p>Security isn’t about perfect versus imperfect or about better versus worse, it’s about <em>this</em> attack surface versus <em>that</em> attack surface.</p>
</blockquote>

<p>You can’t just add more crypto junk to something and expect to somehow get better security. You have to consider what it is buying you, and what it’s costing you.</p>

<p>Full-disk encryption buys you one simple thing: if someone steals your device while the encrypted volume is locked, they probably can’t read it.</p>

<p>If the encrypted volume is unlocked, it’s over; and that’s the state it’s probably usually in. If the key lives in RAM (it usually does), there’s a variety of ways that can be extracted. There’s devices that have complete direct memory access, including everything that speaks FireWire or has FireWire-compatibility built-in. Even if you shut off your machine, cold boot attacks mean that the key can be extracted for a limited about of time. Various jurisdictions can try to force you to hand over the keys.</p>

<p>If an attacker can write to the (encrypted!) volume, it’s probably over. Virtually all sector-level full-disk encryption formats are unauthenticated (with good reason), they’re all malleable and vulnerable to (adaptive) chosen-ciphertext attacks.</p>

<p>If you’re encrypting files or blobs of data within other files, an authenticated encryption scheme like GPG is far more useful.</p>

<p>Don’t get me wrong. Full-disk encryption is a good idea, and you should do it. I’m just saying that what it actually protects against is pretty limited. If there’s files you want to keep secret, full-disk encryption is probably not enough.</p>

<p>For more details, try Thomas &amp; Erin Ptacek’s <a href="http://sockpuppet.org/blog/2014/04/30/you-dont-want-xts/">blog post</a> on why XTS isn’t what you want. XTS is a way to build tweakable ciphers that can be used to create full-disk encryption; but the post applies to full-disk encryption generically as well.</p>

<h3 id="truecrypt_as_a_fulldisk_encryption_mechanism">TrueCrypt as a full-disk encryption mechanism</h3>

<p>So, you probably want full-disk encryption, and you probably want to make sure that sensitive data is encrypted on top of that. Great. What full-disk encryption scheme do you use?</p>

<p>I don’t want to bash TrueCrypt. It is (was, perhaps?) a great go-to project for full-disk encryption. It got a lot of things right. It also got a bunch of things wrong.</p>

<p>TrueCrypt was made by a bunch of people we don’t know occasionally throwing a bunch of binaries over the wall. The source is available (under a non-OSI license), so you could audit that and compile your own binaries, but the truth is that the vast majority of TrueCrypt users never actually did that.</p>

<p>The TrueCrypt disk format and encryption standards are a bit iffy. It has terrible file system support. It has major performance issues, partially due to questionable cryptographic practices such as cipher cascades. It was great for when it was originally conceived and full-disk encryption was still new and exciting, it’s still pretty decent now, but we can certainly do better.</p>

<h3 id="what_actually_happened_to_the_website">What actually happened to the website?</h3>

<p>We don’t really know. There’s a couple of guesses.</p>

<p>First of all, it looks like it are the original authors that folded: the key is the same one that was being used to sign releases months ago. Of course, that could mean that it was compromised or that they were forced to hand it over.</p>

<p>Since the DNS records changed, the e-mail server behavior changed, the same key was used, the Sourceforge client was involved, and fairly major changes to the source code were involved, it’s unlikely that it’s a simple defacement.</p>

<p>It’s unlikely that they folded because they felt discovery of some backdoor was imminent. Folding would actually stop that discovery, because the source was already open.</p>

<p>It’s strange that they would point to alternatives like Bitlocker for Windows and even more dubious alternatives for other operating systems. The authors certainly knew that this would not be an acceptable alternative for the vast majority of their users.</p>

<p>Additionally, the support window for XP ending isn’t a particularly convincing impetus for migrating away from TrueCrypt <em>right now</em>. This has lead some to believe that it’s an automated release. Worse, it could be a gagged response: a big and powerful three-letter agency might be twisting their arm and forcing them to fold, in return for something else (like, say, not being thrown in a Gitmo cell and forgotten about). Again: pure speculation.</p>

<p>Another option is that some of the developers just really, genuinely folded. They felt that for atechnical users, BitLocker was good enough, while the particularly discerning TrueCrypt user would be able to find some other alternative.</p>

<p>Bottom line is that none of this really matters. What matters is what you should do next if you want to have full-disk encryption.</p>

<h3 id="so_what_do_i_do_now">So what do I do now?</h3>

<p>I think LUKS is probably the best system that we have right now, and one of the few that actually improves on TrueCrypt.</p>

<p>If you’re on Linux, dm-crypt + cryptsetup + LUKS is probably what you want. If you’re on OS X, FileVault 2 is probably what you want. If you’re on Windows, your options are looking a bit thin right now:</p>

<ul>
<li>Keep using old versions of TrueCrypt.</li>

<li>Give up and use BitLocker.</li>

<li>Use a Linux virtual machine to use dm-crypt/LUKS, eventually migrating to native support.</li>
</ul>

<p>Personally, I think the first option is the most reasonable right now, and then wait until someone actually writes the native LUKS support.</p>

<p>Oh, and you should probably install GPG to encrypt some of those files stored on that encrypted volume.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[More on Financial Aid Grant Optimization]]></title>
    <link href="http://www.lvh.io/blog/2014/04/06/more-on-financial-aid-grant-optimization/"/>
    <updated>2014-04-06T20:34:27+02:00</updated>
    <id>http://www.lvh.io/blog/2014/04/06/more-on-financial-aid-grant-optimization</id>
    <content type="html"><![CDATA[
<p>In <a href="http://www.lvh.io/blog/2014/03/10/optimization-problems-and-pycon-financial-aid/">a previous post</a>, I talked about ways to optimize PyCon financial aid grants. This is a follow-up on those efforts. Quick recap:</p>

<ul>
<li>There is a fixed budget $b$ available for grants, between 100k and 200k USD.</li>

<li>There are a number of people (approximately 300) requesting various amounts $r_i$ (approximately between 100 USD and 2000 USD) of financial aid, and receive a grant $g_i$ so that $0 \le g_i \le r_i$.</li>

<li>Financial aid applicants can be assigned scores $s_i$, a relative value describing how much we’d like to have them at PyCon.</li>

<li>PyCon wants to optimize the total expected value of scores. That means getting as many people as possible to come, weighted by score.</li>

<li>We’ve conjectured that we can estimate the probability $p_i$ that someone attends as either $g_i/r_i$, or $(g_i/r_i)^2$. The former prefers to spread the budget across a larger number of smaller grants, whereas the latter prefers to focus the budget into a smaller number of larger grants.</li>
</ul>

<p>If any of that doesn’t make sense, you should read <a href="http://www.lvh.io/blog/2014/03/10/optimization-problems-and-pycon-financial-aid/">the previous blog post</a> for more details.</p>

<p>In short, we’re trying to solve the optimization problem:</p>

<p>$$\max \sum E[S_i] = \sum s_i \cdot p_i$$</p>

<p>Since most optimization texts appear to prefer minimization, alternatively:</p>

<p>$$\min - \sum s_i \cdot p_i$$</p>

<p>Subject to a budget constraint and an individual grant constraint:</p>

<p>$$\sum g_i \le b$$</p>

<p>$$0 \le g_i \le r_i$$</p>

<p>The greater-than-zero constraint for individual grants is fairly important, otherwise the algorithm might casually give you answers like:</p>
<figure class='code'><div class='highlight'><table><tr><td class='gutter'><pre class='line-numbers'><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>k = 1: [ 10.  20. -20.  30.  50.  10.  50.], sum: 150.0</span></code></pre></td></tr></table></div></figure>
<p>That list in the middle are the per-person grants. Notice how the algorithm feels that the third person really ought to pony up some cash so that some of the other people can go to PyCon ;-)</p>

<h2 id="squared_problems">Squared problems</h2>

<p>In the <a href="http://www.lvh.io/blog/2014/03/10/optimization-problems-and-pycon-financial-aid/">previous blog post</a> I ran into issues using a very generic constraint solver. I ended that post saying that I would try to remeedy that by applying a more specific solver that takes advantage of a particular structure of the problem.</p>

<p>When you set $p_i = g_i/r_i$, this turns into a linear programming problem, since $r_i$ is a constant. When you set $p_i = \left(g_i/r_i\right)^2$, it turns into a quadratic programming problem. Turns out there’s two things I missed about the quadratic problem:</p>

<ul>
<li>The resulting problem is not convex. That means it’s (probably) difficult to solve.</li>

<li>The estimated probability that someone will attend falls off sharply as soon as they don’t receive the full amount they requested. At 50% of the requested grant, the estimated probability of attending is only 25%; at 90%, it’s 81%. This is the opposite of what we want.</li>
</ul>

<h2 id="fixing_the_model">Fixing the model</h2>

<p>That doesn’t mean we should put the $(g_i/r_i)^k$ out to pasture: it just means that I didn’t pick the $k$ I really wanted. Specifically, if I were to pick $k=1/2$, I’d get:</p>

<p>$$p_i = \left(\frac{g_i}{r_i}\right)^{1/2} = \sqrt{\frac{g_i}{r_i}}$$</p>

<p>In general, if $k = 1/n$:</p>

<p>$$p_i = \left(\frac{g_i}{r_i}\right)^{1/n} = \sqrt[n]{\frac{g_i}{r_i}}$$</p>

<p>That problem <em>is</em> convex, but it isn’t linear, quadratic, or some other easy specific problem. It’s just constrained multivariate convex optimization. That’s okay, there are still a couple of applicable optimization algorithms.</p>

<p>Some of these algorithms require the derivative of the goal function with respect to a particular grant size $g_j$ at a particular point. In case we don’t have the real derivative, we can still provide a numerical approximation. In our case, we don’t really need to approximate, since the derivatives are fairly easy to compute analytically:</p>

<p>$$\frac{\partial}{\partial g_j} \sum_i s_i \cdot \sqrt[n]{\frac{g_i}{r_i}} = \frac{s_j \cdot {g_j}^{\frac{1}{n} - 1}}{\sqrt[n]{r_j} \cdot n}$$</p>

<h2 id="finding_a_solution_with_python">Finding a solution with Python</h2>

<p>There are a few Python packages that contain optimization algorithms:</p>

<ul>
<li>SciPy</li>

<li>cvxopt</li>

<li>pyopt</li>
</ul>

<p>Someone originally pointed me towards cvxopt. While I’m sure it’s excellent software, I already knew SciPy, so I went with that.</p>

<p>SciPy’s optimization module provides the following algorithms:</p>

<ul>
<li><code>fmin_l_bfgs_b</code> - Zhu, Byrd, and Nocedal’s constrained optimizer</li>

<li><code>fmin_tnc</code> - Truncated Newton code</li>

<li><code>fmin_cobyla</code> - Constrained optimization by linear approximation</li>

<li><code>fmin_slsqp</code> - Minimization using sequential least-squares programming</li>

<li><code>nnls</code> - Linear least-squares problem with non-negativity constraint</li>
</ul>

<p>The first two are not applicable because they only appear to support bounds on individual variables. I also need a constraint over the <em>sum</em> of variables for the budget: $\sum g_i \le b$. The last one isn’t applicable because this isn’t a linear least-squares problem. That leaves <code>cobyla</code> and <code>slsqp</code>.</p>

<h2 id="experimenting_with_linear_approximation_cobyla">Experimenting with linear approximation (COBYLA)</h2>

<p>Making COBYLA work ended up being pretty easy. The only non-trivial part is expressing all your constraints as expressions greater than or equal to zero.</p>

<p>I’ve uploaded my IPython notebook (<a href="http://nbviewer.ipython.org/gist/lvh/10107818">viewer</a>, <a href="https://gist.github.com/lvh/10107818">gist</a>).</p>

<p>This produced the following results:</p>
<figure class='code'><div class='highlight'><table><tr><td class='gutter'><pre class='line-numbers'><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>scores: [1 1 1 2 3 5 5]
</span><span class='line'>requested: [10 20 30 30 50 10 50] total: 200, budget: 150
</span><span class='line'>k = 1/0.5: [ 10.  20.  30.  30.  50.  10.   0.], sum: 150.0
</span><span class='line'>k = 1/1: [ 10.  -0.   0.  30.  50.  10.  50.], sum: 150.0
</span><span class='line'>k = 1/2: [ 10.  10.   7.  27.  36.  10.  50.], sum: 150.0
</span><span class='line'>k = 1/3: [ 10.  11.   9.  25.  35.  10.  50.], sum: 150.0
</span><span class='line'>k = 1/5: [ 10.  11.  10.  24.  35.  10.  50.], sum: 150.0
</span><span class='line'>k = 1/10: [ 10.  11.  11.  23.  35.  10.  50.], sum: 150.0
</span><span class='line'>k = 1/100: [ 10.  11.  11.  23.  34.  10.  50.], sum: 150.0</span></code></pre></td></tr></table></div></figure>
<p>Some takeaways:</p>

<ul>
<li>As predicted, as $1/k$ increases, the optimization gradually starts spreading the budget out more evenly; preferring to give many partial grants rather than a few large ones.</li>

<li>This effect is mostly only pronounced for $1/k = 2, 3$; after that, increasing $1/k$ doesn’t make much of a difference anymore. This is what I’d expect when I visualize the $p_i$ functions in my head, but I haven’t ruled out numerical instability.</li>

<li>Even at high $1/k$, the two high scorers get their full grant amount. That’s quite understandable for the one that’s only asking for 10, but even the one asking for a large grant gets it unconditionally. This probably means that tweaking the scoring functions is going to be very important.</li>

<li>The linear version is apparently already quite brutal: the person with score 3 requesting 50 simply gets it entirely, leaving no budget left over for the people with score 1.</li>
</ul>

<p>Since I’m so pleased with these results, I’m skipping <code>slsqp</code> until I feel like it. Next up, I’ll try to compare the COBYLA results above with the results of the greedy algorithm under various fitness metrics.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Optimal Hotel Room Pairing]]></title>
    <link href="http://www.lvh.io/blog/2014/03/18/optimal-hotel-room-pairing/"/>
    <updated>2014-03-18T13:05:52+01:00</updated>
    <id>http://www.lvh.io/blog/2014/03/18/optimal-hotel-room-pairing</id>
    <content type="html"><![CDATA[
<p>The greedy hotel pairing algorithm from my <a href="http://blog.lvh.io/blog/2014/03/10/optimization-problems-and-pycon-financial-aid/">previous post</a> gives good solutions. If you make some fairly reasonable-sounding assumptions about the problem, <em>very</em> good solutions. At any rate nicer than forcing a human to drudge through it; both in terms of person-hours spent and quality of the solutions.</p>

<p>However, it turns out I was wrong about them being <em>optimal</em> solutions. There’s no guarantee they would be, and in fact a good chance that they won’t.</p>

<h2 id="finding_optimal_solutions">Finding optimal solutions</h2>

<p>The good news is that there is a way to find the optimal solution. This problem can be modeled as a <a href="https://en.wikipedia.org/wiki/Matching_%28graph_theory%29">graph matching problem</a>; what we’re trying to find is a weighted maximal matching.</p>

<p>This is really easy if the graph is bipartite, but in our case we’re actually dealing with two <a href="https://en.wikipedia.org/wiki/Complete_graph">complete graphs</a>: we try to pair people with similar gender. Within that compatible group, anyone can theoretically pair with anyone.</p>

<p><img src='https://upload.wikimedia.org/wikipedia/commons/8/86/10-simplex_graph.svg' /></p>

<p>People interested in additional reading might be interested in:</p>

<ul>
<li><a href="http://theory.stanford.edu/~jvondrak/CS369P-files/lec6.pdf">Notes from a Stanford course by Jan Vondrak</a></li>

<li><a href="http://www-sop.inria.fr/members/Frederic.Havet/Cours/matching.pdf">Notes from an Inria course by Frederic Havet</a></li>
</ul>

<h2 id="picking_an_algorithm">Picking an algorithm</h2>

<p>There are several feasible algorithms for this.</p>

<ul>
<li><a href="https://en.wikipedia.org/wiki/Blossom_algorithm">Edmonds’ blossom algorithm</a>, the first polynomial-time algorithm with running time $O(V^4)$ or $O(V^2\cdot E)$</li>

<li>Gabow’s 1973 PhD thesis, an $O(V^3)$ algorithm</li>

<li><a href="http://dl.acm.org/citation.cfm?id=1382663">An $O(\sqrt{V} \cdot E)$ improvement</a> by Micali (yes, <a href="https://en.wikipedia.org/wiki/Silvio_Micali"><em>that</em> Micali</a>) and Vazirani</li>

<li>Another improvement by Gabow, $O(V(E + \log{V}))$</li>
</ul>

<p>The current state of the art in computerized algorithms appears to be <a href="http://pub.ist.ac.at/~vnk/papers/blossom5.pdf">Blossom V</a> by Vladimir Kolmogorov. This algorithm finds <em>perfect</em> matchings (i.e. all nodes are included), which may be impossible for us, e.g. because of an odd number of pairs.</p>

<h2 id="issues">Issues</h2>

<p>One issue with this approach is that it becomes pretty much impossible to adapt this to rooms for more than two people. In order to support that case my previous greedy algorithm remains the best thing I’ve found.</p>

<p>I was unable to find an implementation of this in Java or Clojure. Fortunately, there is a Python library called <a href="http://networkx.lanl.gov">NetworkX</a> that does have <a href="http://networkx.lanl.gov/reference/generated/networkx.algorithms.matching.max_weight_matching.html">an implementation</a>.</p>

<p>I have not yet turned this into a fully functional program, because:</p>

<ul>
<li>it’s too late to apply it for this year</li>

<li>there’s a good chance we won’t be doing this again for next year</li>
</ul>

<h2 id="credits">Credits</h2>

<p>I’d like to thank Tor Myklebust (<code>tmyklebu</code> on Freenode) for pointing out I was wrong, and shoving me in the direction of the answers.</p>

<p>In this blog post I used several freely available graph illustrations from Wikipedia. The complete graph illustrations were made by <a href="https://commons.wikimedia.org/wiki/User:Koko90">koko90</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Optimization Problems and PyCon Financial Aid]]></title>
    <link href="http://www.lvh.io/blog/2014/03/10/optimization-problems-and-pycon-financial-aid/"/>
    <updated>2014-03-10T16:47:00+01:00</updated>
    <id>http://www.lvh.io/blog/2014/03/10/optimization-problems-and-pycon-financial-aid</id>
    <content type="html"><![CDATA[
<p>This year, I have partly taken on some new responsibilities in organizing PyCon. Specifically, I’ve done some work on financial aid. (Next year, I will be taking on the position of financial aid chair.) There have been some challenges that I’ve thrown some code at. Some of it stuck.</p>

<p>I’m very much interested in your comments, thoughts, alternative approaches, et cetera. Hit me up on <a href="https://twitter.com/lvh">Twitter</a>.</p>

<h2 id="hotel_room_allocation">Hotel room allocation</h2>

<p>The first issue I solved was one of hotel room allocation. We provide the financial aid applicants with hotel rooms. To keep costs down, we pair people up, two by two.</p>

<p>We want to pair people so that we have to book a minimal number of days. If there’s days on the start of the room booking where only one person is booking the room, we have to pay for the rest.</p>

<h3 id="a_greedy_algorithm">A greedy algorithm</h3>

<p>I start out with generating every possible pairing. Assuming we have 300 financial aid applicants, that’s:</p>

<p>$${300 \choose 2} = \frac{300!}{2! \cdot 298!} = 44850$$</p>

<p>That’s more than we can check by hand, but still pretty easy for a computer. Besides, there are actually fewer pairs than that: some people request to be paired together explicitly, and we only pair people of the same gender.</p>

<p>Then, I sort them by number of unmatched days, that is, how many days would have a single person in the hotel room if we paired them together. Finally, I just greedily start grabbing pairs, keeping track of the people that have been allocated rooms as I go along. As soon as everyone is accounted for, we stop.</p>

<p>Other than perhaps minding the edge conditions where you have an odd number of people to pair, this isn’t too tricky. The implementation for this is on Github, in <a href="https://github.com/lvh/pairing/blob/master/src/pairing/core.clj"><code>lvh/pairing</code></a>.</p>

<h3 id="solution_meet_reality">Solution, meet reality</h3>

<p>Before I wrote this, humans did this by hand. That took pretty long, and the solutions were decent, but suboptimal. All the humans that have tackled this problem seem to take the same approach: sort by check-in date, find exact or near matches in check-out dates, rinse, repeat.</p>

<p>The algorithm above did quite well, coming up with a significantly better result than the previous human allocation. It also produced very <em>interesting</em> solutions. Turns out that by taking a big hit on one of the pairs (say, a pair that’s 4 days mismatched four days), you can limit the damage on a large number of other pairs, and still come out on top. After reviewing with the person who previously had to do this manually, we quickly agreed that a human would most likely not have come up with this.</p>

<p>Furthermore, a lot of the pairs have matching check-out dates but with a mismatched check-in date; whereas humans typically only look for solutions in the other direction. This is easy to explain in hindsight; the algorithm has no concept of an ordering of events in time. It just tries to minimize the number of mismatched days.</p>

<p>I’m quite happy with the result. Any dollar I’m not devoting to a room that isn’t being fully used will instead be going into an increased grant.</p>

<p>Unfortunately, finding this solution isn’t the end of the story. It rarely survives the clash with reality. Many complex factors affect it: people will drastically change their room dates, people’s visas get denied, et cetera. All sorts of unforseeable circumstances have lead to changes to the answer the algorithm originally produced. I don’t expect that to change until PyCon is over; unfortunately, I also don’t think that’s a problem I can fix in a few lines of Clojure.</p>

<h2 id="grant_allocation">Grant allocation</h2>

<p>The second issue is a much thornier one. Given the financial aid budget, figure out how to optimally distribute it. The budget is quite limited, a good deal smaller than the sum of what everyone requests.</p>

<p>There’s a few reasons why this problem is complex. First of all, “optimal” is highly subjective. As I’m sure you’ll notice very soon after thinking about it, it’s very easy to verge off from math and straight into the realm of politics.</p>

<h3 id="a_very_simple_greedy_algorithm">A very simple greedy algorithm</h3>

<p>You might say that you want to get as many people as possible to come to PyCon, and you just greedily allocate the smallest grant requests first. This has a few disadvantages:</p>

<ol>
<li>It biases against the people that ostensibly need the money the most.</li>

<li>It is ordering-sensitive: equivalent applications that happen to come later in the queue are disadvantaged.</li>

<li>It oversimplifies how people react to grants, by making grant allocation binary. Someone receiving 90% of their requested grant amount will likely still be able to attend. Suppose you have 11 people, all requesting 100 USD, and you have 1000 USD to spend. The greedy algorithm would give the first ten of them 100 USD and find its purse empty for the eleventh. It would almost certainly be better to give them all 90.91 USD instead.</li>

<li>Game-theoretically, it makes a lot of sense for everyone to apply for a small grant that they will almost certainly get. (This is not a real issue for us, because we still have humans eyeballing all the applications.)</li>

<li>The only difference between applications is the amount they’re requesting, but there are people that we would like to bias in favor of. For example, we’d like to try very hard to get speakers or tutorial presenters to the conference, we might want to reward people doing open source work, et cetera.</li>
</ol>

<p>Selecting these critera is definitely squarely in the realm of politics, and I’d like to stick to the realm of math; so let’s just assume that we can assign scores to applicants and that those scores are fair and just. If you feel like we shouldn’t bias in favor of anyone at all, just assume that whenever I say “the score of an applicant” I mean “the number 1”.</p>

<h3 id="a_slightly_smarter_greedy_algorithm">A slightly smarter greedy algorithm</h3>

<p>One of the key ideas (which a lot of people seem to have when tackling this problem) is to translate an application’s score into an amount of the budget. So, for example, let’s say that the sum of all scores is 100, and your score is 10, that means you can have up to 10% of the budget allocated to you.</p>

<p>So, I make a pass over all the remaining applicants. If you’re asking less than your budget slice, you get your requested grant. If you’re asking for more, I save you for a future pass. Even though the budget goes down between passes, budget slices will go up, because the total score drops.</p>

<p>You can’t do this in one pass, increasing the budget as you go along if people request less than their slice, because you might introduce order dependence. For example, consider what happens when Alice and Charlie both need more than the budget allows for (and they have the same score and requested amount), and Bob needs less. If you process them in the order Alice - Bob - Charlie, Charlie may get his requested grant and Alice may not, just because Bob’s in the middle making the budget bigger for Charlie.</p>

<p>Once everyone left is requesting more than their slice, they just get their slice instead of their requested amount.</p>

<p>This solution is adequate, but I’m not completely satisfied; everyone besides the last pass will get full grant amounts. You can find my implementation of this algorithm <a href="https://github.com/lvh/hood/blob/master/src/hood/greedy.clj">on Github</a> as well.</p>

<h3 id="a_better_model">A better model</h3>

<p>I think we can do better by applying some elementary probability theory. What we really want is to maximize the total score of the applicants that we expect to see at PyCon as a consequence of financial aid. Probability theory has a thing called the expected value of a random variable, which is pretty much just the integral of the random variable with respect to the probability. In our case, that just means that we want to maximize the sum of the probabiliies that a given applicant will come to PyCon given a particular grant amount, weighted by their score:</p>

<p>$$\max \sum s_i \cdot p_i$$</p>

<p>That just restates problems we can’t solve in terms of problems we can’t solve. What on earth could the probability that someone shows up be? We can’t know the real value, since it’s specific to each individual, and dependent on a lot of random, unknowable events. We can, however, make an educated guess. If we don’t give them any money, they probably won’t come. If we give them the amount they’re asking for, they probably will.</p>

<p>We could conjecture that the probability someone will come to the conference is approximately the fraction of the amount they requested that they actually received:</p>

<p>$$p_i = \frac{g_i}{r_i}$$</p>

<p>For example, if someone gets 90% of their requested grant, we estimate that the odds they will attend are also 90%; if we give them only 10%, we estimate it at just 10%.</p>

<p>Alternatively, we could conjecture that it’s closer to the <em>square</em> of that ratio; when giving someone a value that’s very close to what they asked for, their probability of attending is still going to be very high; but if we only give them half, the odds they will attend will be closer to 25%, much lower than 50%. So, the expression becomes:</p>

<p>$$p^{\prime}_i = \left(\frac{g_i}{r_i}\right)^{2}$$</p>

<p><em>Update:</em> I now realize that this is probably not the expression that I actually want: it falls off very quickly as soon as an applicant gets anything less than the full amount. I’ve elaborated on this in <a href="http://www.lvh.io/blog/2014/04/06/more-on-financial-aid-grant-optimization/">a new blog post</a>.</p>

<p>We will see how the square model emphasizes focusing the available funds on fewer grants, whereas the linear model will spread smaller grants more liberally.</p>

<h3 id="an_attempt_with_constraint_solvers">An attempt with constraint solvers</h3>

<p>(I would like to thank Mark Engelberg for helping me with the stuff in this chapter. It may not have panned out, but it was a very educational experience nonetheless.)</p>

<p>It’d be nice if we could just declaratively describe the problem, throw it into a computer program, and have it magically tell us the answer. Of course, there are programs that do exactly that, called solvers.</p>

<p>When I reached out on the Clojure mailing list, Mark Engelberg helpfully reached out and immediately handed out some cool runnable example for me to play with. Sure enough, they worked super, and with a carefully crafted three-person example we could clearly see the difference between the linear and quadratic models I was talking about above: under the square model, the concentrated grants, trying harder to give high-scoring applications the amount they requested. The linear model spread money out more evenly. That is, with the following applications:</p>
<figure class='code'><figcaption><span /></figcaption><div class='highlight'><table><tr><td class='gutter'><pre class='line-numbers'><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span class='p'>(</span><span class='k'>def </span><span class='nv'>alice</span> <span class='p'>{</span><span class='ss'>:name</span> <span class='s'>&quot;Alice&quot;</span>, <span class='ss'>:score</span> <span class='mi'>5</span>, <span class='ss'>:requested</span> <span class='mi'>120</span><span class='p'>})</span>
</span><span class='line'><span class='p'>(</span><span class='k'>def </span><span class='nv'>bob</span> <span class='p'>{</span><span class='ss'>:name</span> <span class='s'>&quot;Bob&quot;</span>, <span class='ss'>:score</span> <span class='mi'>4</span>, <span class='ss'>:requested</span> <span class='mi'>100</span><span class='p'>})</span>
</span><span class='line'><span class='p'>(</span><span class='k'>def </span><span class='nv'>carol</span> <span class='p'>{</span><span class='ss'>:name</span> <span class='s'>&quot;Carol&quot;</span>, <span class='ss'>:score</span> <span class='mi'>3</span>, <span class='ss'>:requested</span> <span class='mi'>80</span><span class='p'>})</span>
</span></code></pre></td></tr></table></div></figure>
<p>In a linear model, it comes up with:</p>
<figure class='code'><figcaption><span /></figcaption><div class='highlight'><table><tr><td class='gutter'><pre class='line-numbers'><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span class='p'>{</span><span class='nv'>alice</span> <span class='mi'>120</span>
</span><span class='line'> <span class='nv'>bob</span> <span class='mi'>80</span>
</span><span class='line'> <span class='nv'>carol</span> <span class='mi'>0</span><span class='p'>}</span>
</span></code></pre></td></tr></table></div></figure>
<p>However, in the quadratic model, the optimizer rather gives Carol (who has a lower score) a complete grant than give Bob a partial one:</p>
<figure class='code'><figcaption><span /></figcaption><div class='highlight'><table><tr><td class='gutter'><pre class='line-numbers'><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span class='p'>{</span><span class='nv'>alice</span> <span class='mi'>120</span>
</span><span class='line'> <span class='nv'>bob</span> <span class='mi'>0</span>
</span><span class='line'> <span class='nv'>carol</span> <span class='mi'>80</span><span class='p'>}</span>
</span></code></pre></td></tr></table></div></figure>
<p>You can find the code <a href="https://github.com/lvh/hood/blob/master/src/hood/constraint.clj">on Github</a>. The tests that confirm the difference in behavior for the linear and quadratic models are in <a href="https://github.com/lvh/hood/blob/master/test/hood/constraint_test.clj">the tests</a>.</p>

<p>There’s one issue though; it didn’t scale. Not bad enough that you’d notice on the three-person example (I thought my REPL was just being laggy), but bad enough that any real-world problem would be completely unsolvable. Why? Clearly constraint solvers are awesome real world tools with real world usage, it’s not like they’re supposed to fall over as soon as you throw a problem of reasonable size at it.</p>

<p>Well, let’s do some napkin math. If we have 200 financial aid recipients that are all getting 1000 possible options (somewhere between 0 USD and 1000 USD, in whole-dollar increments), there’s 200,000 possible places to put any given dollar. If we have 100,000 USD to spend, that’s:</p>

<p>$${2 \cdot 10^{5} \choose 10^{5}} = \frac{(2 \cdot 10^{5})!}{10^{5}! \cdot 10^{5}!} \approx 10^{60203}$$</p>

<p>That is a very big number. I needed logarithms to compute it. It is so huge that it makes the number of atoms in the observable universe (about $10^{80}$) look like rounding error.</p>

<p>In an attempt to “fix” that problem, I tried only handing out funds in chunks of 100 USD each. Then, we have 1000 chunks to hand out and 2000 places to put them:</p>

<p>$${2000 \choose 1000} = \frac{2000!}{1000! \cdot 1000!} \approx 10^{600}$$</p>

<p>I have made the problem 59,603 decimal orders of magnitude easier! Rejoice!</p>

<p>A constraint solver really doesn’t “know” anything about the structure of the problem you’re feeding it. That’s a trade-off: in return, it grants you a lot of freedom in expressing your problem. Constraint solvers like LoCo are very valuable, they just aren’t a good fit for this problem. They are designed for problems where the constraints really constraining the solution space. We’re clearly not in that territory. We have many valid solutions, and we’re struggling to look for a <em>good</em> one.</p>

<p>There are two ways we can fix this:</p>

<ol>
<li>Compromising on the freedom of expressing the problem. By pouring our problem into a specific structured shape, we may be able to use a much faster solver, specific to that class of problems. Also, by allowing arbitrary real numbers instead of just integers, we can use much faster solvers.</li>

<li>Compromising on finding the <em>optimal</em> solution, instead searching for a <em>decent</em> solution. You can do that with algorithms like tabu search or simulated annealing.</li>
</ol>

<p>I will be elaborating on these problems in a future blog post.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[External Drive Lossage on Mavericks]]></title>
    <link href="http://www.lvh.io/blog/2013/12/18/external-drive-lossage-on-mavericks/"/>
    <updated>2013-12-18T11:22:00+01:00</updated>
    <id>http://www.lvh.io/blog/2013/12/18/external-drive-lossage-on-mavericks</id>
    <content type="html"><![CDATA[
<p>Welp, my WD 1TB Passport drive borked. Seems to be a <a href="https://discussions.apple.com/thread/5475136">common issue on Mavericks</a> with a select number of drives, including this one, apparently…</p>

<p>Common themes:</p>

<ol>
<li>Started with OS X complaining at me because I supposedly ejected the drive unsafely, even though the drive was still in the USB slot.</li>

<li>Drive isn’t mounted automatically anymore. Console says filesystem is busted: <code>17/12/13 20:18:35,000 kernel[0]: hfs: Runtime corruption
detected on My Passport, fsck will be forced on next mount.</code></li>

<li>Drive can’t be /unmounted/ using Disk Utility either both in regular desktop mode and in recovery mode (booting with ⌘+R). This means that even trying to just nuke the partition and starting over doesn’t work; it just sits there for a while and then eventually times out saying it can’t unmount the drive.</li>
</ol>

<p>I did not, at any point, have WD’s drive management software installed (unless it managed to do it behind my back). First thing I did was put a new GUID table on it with one partition.</p>

<p>Apparently the solution is to boot into Linux to fix the drive. I’ll let you know how that pans out.</p>

<p>UPDATE: Booted into Linux, was able to read everything. <code>fsck</code> does report something wrong with the filesystem, but not bad enough that I can’t mount or umount it. Was able to salvage what looks to be all the data I wanted; didn’t bother to try and get e.g. Time Machine or Spotlight index data off, which is where I suspect the issues to stem from.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using Protractor With AngularJS and Yeoman]]></title>
    <link href="http://www.lvh.io/blog/2013/11/15/using-protractor-with-angularjs-and-yeoman/"/>
    <updated>2013-11-15T11:29:00+01:00</updated>
    <id>http://www.lvh.io/blog/2013/11/15/using-protractor-with-angularjs-and-yeoman</id>
    <content type="html"><![CDATA[
<p>In writing the website for Crypto 101, my upcoming book, I’ve been toying around with AngularJS. The basic setup was done using Yeoman.</p>

<p>First of all, the Yeoman Angular generator gives you a <code>karma-e2e.conf.js</code>, but doesn’t really configure grunt to do any end-to-end testing. Turns out that the new hotness for Angular scenario testing is based on Protractor. Karma isn’t deprecated, it’s just for unit tests. Protractor is based on Selenium, which is probably an upgrade :-)</p>

<p>Anyway, here’s what I had to do to get started.</p>

<ol>
<li>In the root of your app, install protractor and the Selenium standalone server.</li>
</ol>
<figure class='code'><div class='highlight'><table><tr><td class='gutter'><pre class='line-numbers'><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>npm install --save-dev protractor
</span><span class='line'>./node_modules/protractor/bin/install_selenium_standalone</span></code></pre></td></tr></table></div></figure>
<ol>
<li>
<p>Optionally, add <code>selenium</code> to your <code>.gitignore</code>, since it contains a ~30MB binary that doesn’t belong in your git repo.</p>
</li>

<li>
<p>Add a <code>protractor.conf.js</code> file. Here’s mine. Remember that there’s some stuff in there for you to uncomment, so don’t just copy paste. On my machine, the default driver was Internet Explorer for Windows, which is strange given that I’m running on OS X. Oh well. This uses Chrome instead.</p>
</li>
</ol>
<figure class='code'><figcaption><span /></figcaption><div class='highlight'><table><tr><td class='gutter'><pre class='line-numbers'><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class='nx'>exports</span><span class='p'>.</span><span class='nx'>config</span> <span class='o'>=</span> <span class='p'>{</span>
</span><span class='line'>  <span class='nx'>seleniumAddress</span><span class='o'>:</span> <span class='s1'>&#39;http://localhost:4444/wd/hub&#39;</span><span class='p'>,</span>
</span><span class='line'>  <span class='nx'>specs</span><span class='o'>:</span> <span class='p'>[</span>
</span><span class='line'>    <span class='c1'>// To run plain JS files, uncomment the following line:</span>
</span><span class='line'>    <span class='c1'>// &#39;./test/integration/*.js&#39;,</span>
</span><span class='line'>    <span class='c1'>// To run Coffeescript files, uncomment the following line:</span>
</span><span class='line'>    <span class='c1'>// &#39;.tmp/integration/*.js&#39;</span>
</span><span class='line'>  <span class='p'>],</span>
</span><span class='line'>
</span><span class='line'>  <span class='c1'>// Set capabilities.</span>
</span><span class='line'>  <span class='nx'>capabilities</span><span class='o'>:</span> <span class='p'>{</span>
</span><span class='line'>    <span class='s1'>&#39;browserName&#39;</span><span class='o'>:</span> <span class='s1'>&#39;chrome&#39;</span>
</span><span class='line'>  <span class='p'>},</span>
</span><span class='line'>
</span><span class='line'>  <span class='nx'>jasmineNodeOpts</span><span class='o'>:</span> <span class='p'>{</span>
</span><span class='line'>    <span class='nx'>showColors</span><span class='o'>:</span> <span class='kc'>true</span><span class='p'>,</span>
</span><span class='line'>    <span class='nx'>defaultTimeoutInterval</span><span class='o'>:</span> <span class='mi'>30000</span>
</span><span class='line'>  <span class='p'>}</span>
</span><span class='line'><span class='p'>}</span>
</span></code></pre></td></tr></table></div></figure>
<ol>
<li>If you’re using Coffeescript, change your Gruntfile to build your integration tests:</li>
</ol>
<figure class='code'><figcaption><span /></figcaption><div class='highlight'><table><tr><td class='gutter'><pre class='line-numbers'><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'>  <span class='nx'>grunt</span><span class='p'>.</span><span class='nx'>initConfig</span><span class='p'>({</span>
</span><span class='line'>    <span class='c1'>// ...</span>
</span><span class='line'>    <span class='nx'>coffee</span><span class='o'>:</span> <span class='p'>{</span>
</span><span class='line'>      <span class='c1'>// ...</span>
</span><span class='line'>      <span class='nx'>test</span><span class='o'>:</span> <span class='p'>{</span>
</span><span class='line'>        <span class='nx'>files</span><span class='o'>:</span> <span class='p'>[</span>
</span><span class='line'>        <span class='c1'>// ...</span>
</span><span class='line'>        <span class='p'>{</span>
</span><span class='line'>          <span class='nx'>expand</span><span class='o'>:</span> <span class='kc'>true</span><span class='p'>,</span>
</span><span class='line'>          <span class='nx'>cwd</span><span class='o'>:</span> <span class='s1'>&#39;test/integration&#39;</span><span class='p'>,</span>
</span><span class='line'>          <span class='nx'>src</span><span class='o'>:</span> <span class='s1'>&#39;{,*/}*.coffee&#39;</span><span class='p'>,</span>
</span><span class='line'>          <span class='nx'>dest</span><span class='o'>:</span> <span class='s1'>&#39;.tmp/integration&#39;</span><span class='p'>,</span>
</span><span class='line'>          <span class='nx'>ext</span><span class='o'>:</span> <span class='s1'>&#39;.js&#39;</span>
</span><span class='line'>        <span class='p'>}]</span>
</span><span class='line'>      <span class='p'>}</span>
</span><span class='line'>    <span class='p'>},</span>
</span><span class='line'>  <span class='c1'>// ...</span>
</span><span class='line'><span class='p'>})</span>
</span></code></pre></td></tr></table></div></figure>
<ol>
<li>
<p>Write some tests in <code>test/integration</code>.</p>
</li>

<li>
<p>You can now manually run your tests. First run Selenium:</p>
</li>
</ol>
<figure class='code'><figcaption><span /></figcaption><div class='highlight'><table><tr><td class='gutter'><pre class='line-numbers'><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class='p'>.</span><span class='o'>/</span><span class='nx'>node_modules</span><span class='o'>/</span><span class='nx'>protractor</span><span class='o'>/</span><span class='nx'>bin</span><span class='o'>/</span><span class='nx'>install_selenium_standalone</span>
</span></code></pre></td></tr></table></div></figure>
<p>Then run your tests:</p>
<figure class='code'><figcaption><span /></figcaption><div class='highlight'><table><tr><td class='gutter'><pre class='line-numbers'><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class='p'>.</span><span class='o'>/</span><span class='nx'>node_modules</span><span class='o'>/</span><span class='nx'>protractor</span><span class='o'>/</span><span class='nx'>bin</span><span class='o'>/</span><span class='nx'>protractor</span> <span class='nx'>protractor</span><span class='p'>.</span><span class='nx'>conf</span><span class='p'>.</span><span class='nx'>js</span>
</span></code></pre></td></tr></table></div></figure>
<p>Once I figure out the proper way to do this in Grunt, I’ll let you know.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Thoughts on RDRAND in Linux]]></title>
    <link href="http://www.lvh.io/blog/2013/10/19/thoughts-on-rdrand-in-linux/"/>
    <updated>2013-10-19T21:47:00+02:00</updated>
    <id>http://www.lvh.io/blog/2013/10/19/thoughts-on-rdrand-in-linux</id>
    <content type="html"><![CDATA[
<p>This has been brewing since I read <a href="https://www.change.org/en-GB/petitions/linus-torvalds-remove-rdrand-from-dev-random-4/responses/9066">Linus’ response to the petition to remove <code>RDRAND</code> from /dev/random</a>.</p>

<p>For those of you who don’t know, <code>RDRAND</code> is a CPU instruction introduced by Intel on recent CPUs. It (supposedly) uses a hardware entropy source, and runs it through AES in CBC-MAC mode, to produce random numbers.</p>

<p>Out of fear that <code>RDRAND</code> may somehow be backdoored, someone petitioned to remove <code>RDRAND</code> support to “improve the overall security of the kernel”. If <code>RDRAND</code> contains a back door, and an unknown attacker can control the output, that could break pretty much all userland crypto.</p>

<p>Linus fulminated, as he is wont to do. He suggested we go read <code>drivers/char/random.c</code>. I quote (expletives and insults omitted):</p>

<p>&gt; we use rdrand as <em>one</em> of many inputs into the random pool, and we &gt; use it as a way to <em>improve</em> that random pool. So even if rdrand &gt; were to be back-doored by the NSA, our use of rdrand actually &gt; improves the quality of the random numbers you get from &gt; /dev/random.</p>

<p>I went ahead and read <code>random.c</code>. You can read it for yourself <a href="https://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/tree/drivers/char/random.c">in Linus’ tree</a>.</p>

<p>Disclaimer: I am not an expert in this piece of code. I have no doubt Linus is far more familiar with it than I am. I’d love to be proven wrong. I’m just taking his advice and reading some code.</p>

<p>The function I’m interested in is <code>extract_buf</code>:</p>
<figure class='code'><figcaption><span /></figcaption><div class='highlight'><table><tr><td class='gutter'><pre class='line-numbers'><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='c'><span class='line'>    <span class='cm'>/*</span>
</span><span class='line'><span class='cm'>	 * If we have a architectural hardware random number</span>
</span><span class='line'><span class='cm'>	 * generator, mix that in, too.</span>
</span><span class='line'><span class='cm'>	 */</span>
</span><span class='line'>	<span class='k'>for</span> <span class='p'>(</span><span class='n'>i</span> <span class='o'>=</span> <span class='mi'>0</span><span class='p'>;</span> <span class='n'>i</span> <span class='o'>&lt;</span> <span class='n'>LONGS</span><span class='p'>(</span><span class='n'>EXTRACT_SIZE</span><span class='p'>);</span> <span class='n'>i</span><span class='o'>++</span><span class='p'>)</span> <span class='p'>{</span>
</span><span class='line'>		<span class='kt'>unsigned</span> <span class='kt'>long</span> <span class='n'>v</span><span class='p'>;</span>
</span><span class='line'>		<span class='k'>if</span> <span class='p'>(</span><span class='o'>!</span><span class='n'>arch_get_random_long</span><span class='p'>(</span><span class='o'>&amp;</span><span class='n'>v</span><span class='p'>))</span>
</span><span class='line'>			<span class='k'>break</span><span class='p'>;</span>
</span><span class='line'>		<span class='n'>hash</span><span class='p'>.</span><span class='n'>l</span><span class='p'>[</span><span class='n'>i</span><span class='p'>]</span> <span class='o'>^=</span> <span class='n'>v</span><span class='p'>;</span>
</span><span class='line'>	<span class='p'>}</span>
</span></code></pre></td></tr></table></div></figure>
<p>This is in the extraction phase. This is after the hash is being mixed back in to the pool (and that’s for backtracking attacks: not intended as an input to the pool). It seems to me like the output of <code>arch_get_random_long</code> is being XORed in with the extracted output, not with the pool.</p>

<p>If I were to put on my tin-foil hat, I would suggest that the difficulty has now been moved from being able to subvert the pool as one of its entropy sources (which we think is impossible), versus being able to see what you’re about to be XORed with. The latter seems a lot closer to the realm of stuff a microcode instruction can do.</p>

<p>To put it into Python:</p>
<figure class='code'><figcaption><span /></figcaption><div class='highlight'><table><tr><td class='gutter'><pre class='line-numbers'><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class='kn'>from</span> <span class='nn'>inspect</span> <span class='kn'>import</span> <span class='n'>currentframe</span>
</span><span class='line'><span class='kn'>from</span> <span class='nn'>random</span> <span class='kn'>import</span> <span class='n'>getrandbits</span>
</span><span class='line'>
</span><span class='line'><span class='k'>def</span> <span class='nf'>extract_buf</span><span class='p'>():</span>
</span><span class='line'>    <span class='sd'>&quot;&quot;&quot;Gets 16 bytes from the pool, and mixes them with RDRAND output.</span>
</span><span class='line'>
</span><span class='line'><span class='sd'>    &quot;&quot;&quot;</span>
</span><span class='line'>    <span class='n'>pool_bits</span> <span class='o'>=</span> <span class='n'>extract_from_pool</span><span class='p'>()</span>
</span><span class='line'>    <span class='n'>rdrand_bits</span> <span class='o'>=</span> <span class='n'>rdrand</span><span class='p'>()</span>
</span><span class='line'>    <span class='k'>return</span>  <span class='n'>pool_bits</span> <span class='o'>^</span> <span class='n'>rdrand_bits</span>
</span><span class='line'>
</span><span class='line'><span class='k'>def</span> <span class='nf'>extract_from_pool</span><span class='p'>():</span>
</span><span class='line'>    <span class='sd'>&quot;&quot;&quot;Pretend to get some good, unpredictable bytes from the pool.</span>
</span><span class='line'>
</span><span class='line'><span class='sd'>    Actually gets a long with some non-cryptographically secure random</span>
</span><span class='line'><span class='sd'>    bits from random.getrandbits, which is usually a Mersenne Twister.</span>
</span><span class='line'>
</span><span class='line'><span class='sd'>    &quot;&quot;&quot;</span>
</span><span class='line'>    <span class='k'>return</span> <span class='n'>getrandbits</span><span class='p'>(</span><span class='mi'>32</span><span class='p'>)</span>
</span><span class='line'>
</span><span class='line'><span class='k'>def</span> <span class='nf'>rdrand</span><span class='p'>():</span>
</span><span class='line'>    <span class='sd'>&quot;&quot;&quot;</span>
</span><span class='line'><span class='sd'>    A malicious hardware instruction.</span>
</span><span class='line'><span class='sd'>    &quot;&quot;&quot;</span>
</span><span class='line'>    <span class='n'>pool_bits</span> <span class='o'>=</span> <span class='n'>currentframe</span><span class='p'>()</span><span class='o'>.</span><span class='n'>f_back</span><span class='o'>.</span><span class='n'>f_locals</span><span class='p'>[</span><span class='s'>&quot;pool_bits&quot;</span><span class='p'>]</span>
</span><span class='line'>    <span class='k'>return</span> <span class='n'>pool_bits</span> <span class='o'>^</span> <span class='mh'>0xabad1dea</span>
</span><span class='line'>
</span><span class='line'><span class='k'>if</span> <span class='n'>__name__</span> <span class='o'>==</span> <span class='s'>&quot;__main__&quot;</span><span class='p'>:</span>
</span><span class='line'>    <span class='k'>assert</span> <span class='n'>extract_buf</span><span class='p'>()</span> <span class='o'>==</span> <span class='mh'>0xabad1dea</span>
</span></code></pre></td></tr></table></div></figure>
<p>Why can’t RDRAND work like this?</p>

<p>Some comments based on feedback I’ve gotten so far:</p>

<ol>
<li>This attack does not need to know where the PRNG state lives in memory. First of all, this isn’t an attack on the PRNG state, it’s on the PRNG output. Secondly, the instruction only needs to peek ahead at what is about to happen (specifically, what’s about to be XORed with) the RDRAND output. That doesn’t require knowing where the PRNG state (or its output) is being stored in memory; we’re already talking register level at that point.</li>

<li>While it’s certainly true that if you can’t trust the CPU, you can’t trust anything, that doesn’t really make this problem go away. <code>RDRAND</code> being broken wouldn’t make software crash, which is a lot harder for almost all other instructions. <code>RDRAND</code> being broken wouldn’t result in measurable side-effects, unlike what would happen if <code>PCLMULDQ</code> contained a back door. Furthermore, it’s a lot easier to backdoor one single microcode instruction and a lot more plausible and feasible for a CSPRNG to be backdoored than it is to think of a CPU as some kind of intelligent being that’s actively malicious or being remotely controlled.</li>
</ol>

<p>For what it’s worth, it seems <a href="https://twitter.com/zooko/status/392334674690723840">Zooko agrees with me</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Securing Against Timing Attacks With Twisted]]></title>
    <link href="http://www.lvh.io/blog/2013/01/30/securing-against-timing-attacks-with-twisted/"/>
    <updated>2013-01-30T18:55:00+01:00</updated>
    <id>http://www.lvh.io/blog/2013/01/30/securing-against-timing-attacks-with-twisted</id>
    <content type="html"><![CDATA[
<h2 id="what_are_timing_attacks">What are timing attacks?</h2>

<p>Timing attacks are side-channel attacks that rely on inferring secret information from operations by measuring how long they take to execute.</p>

<p>A complete explanation is outside of the scope of this article, but the <a href="https://en.wikipedia.org/wiki/Timing_attack">Wikipedia article</a> might be a good starting point for the interested reader.</p>

<h2 id="why_should_i_care_about_them">Why should I care about them?</h2>

<p>Because they can creep in before you know it, and break your otherwise fine system.</p>

<p>A common way they’re introduced are string comparisons. String comparisons in many langauge implementations, including all implementations of Python I know of, short-circuit. They work roughly like this:</p>
<figure class='code'><div class='highlight'><table><tr><td class='gutter'><pre class='line-numbers'><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class='k'>def</span> <span class='nf'>strcmp</span><span class='p'>(</span><span class='n'>s1</span><span class='p'>,</span> <span class='n'>s2</span><span class='p'>):</span>
</span><span class='line'>    <span class='k'>if</span> <span class='nb'>len</span><span class='p'>(</span><span class='n'>s1</span><span class='p'>)</span> <span class='o'>!=</span> <span class='nb'>len</span><span class='p'>(</span><span class='n'>s2</span><span class='p'>):</span>
</span><span class='line'>        <span class='k'>return</span> <span class='bp'>False</span>
</span><span class='line'>    <span class='k'>for</span> <span class='n'>c1</span><span class='p'>,</span> <span class='n'>c2</span> <span class='ow'>in</span> <span class='nb'>zip</span><span class='p'>(</span><span class='n'>s1</span><span class='p'>,</span> <span class='n'>s2</span><span class='p'>):</span>
</span><span class='line'>        <span class='k'>if</span> <span class='n'>c1</span> <span class='o'>!=</span> <span class='n'>c2</span><span class='p'>:</span>
</span><span class='line'>            <span class='k'>return</span> <span class='bp'>False</span>
</span><span class='line'>    <span class='k'>return</span> <span class='bp'>True</span>
</span></code></pre></td></tr></table></div></figure>
<p>This means that as soon as they can prove the two strings are not equal, they return <code>False</code> and ignore the rest of the string. This is a very simple and effective performance optimization. And that’s precisely why, from a security point of view, it’s a liability.</p>

<p>Since it takes longer to compare “The quick brown fox jumps over the lazy dog” to “The quick brown fox jumps over the lazy god” than it does to compare it to “Lorem ipsum”, or even a Lipsum of the same length, an attacker can use that timing information to figure out what the original string is that is being compared to, even when he shouldn’t.</p>

<h2 id="why_did_you_care">Why did you care?</h2>

<p>Password resets.</p>

<p>The typically recommended way of doing them is to generate a random number, one that’s sufficiently long that an attacker can’t guess it. Then, you relay that number to the user using some alternative channel (usually a URL in an e-mail).</p>

<p>Bar the random number, those URLs are predictable. That means an attacker can trivially try any number he wants. If an attacker is allowed to do that enough, he could measure timing differences between different numbers (introduced by string comparison functions that short-circuit or even by the database’s index) to efficiently deduce the value of a “good” number.</p>

<p>Also, if membership is private, an attacker may exploit timing differences in the password reset <em>request</em> function to farm e-mail addresses.</p>

<h2 id="how_do_i_protect_against_timing_attacks">How do I protect against timing attacks?</h2>

<p>Just to be clear: timing attacks are a complicated problem, and this article describes just one strategy I’ve applied to help secure against them.</p>

<p>The easiest way to prevent a timing attack is to make sure that the timing your hypothetical attacker can measure is unrelated to the work you have to do.</p>

<p>Since I was using <a href="http://twistedmatrix.com">Twisted</a> and <a href="http://amp-protocol.net/">AMP</a>, this was actually quite easy. I wrote a decorator for AMP responder functions that does exactly that:</p>
<figure class='code'><div class='highlight'><table><tr><td class='gutter'><pre class='line-numbers'><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class='k'>def</span> <span class='nf'>_immediateResponder</span><span class='p'>(</span><span class='n'>f</span><span class='p'>):</span>
</span><span class='line'>    <span class='sd'>&quot;&quot;&quot;</span>
</span><span class='line'><span class='sd'>    A decorator for responder functions that should return immediately and</span>
</span><span class='line'><span class='sd'>    execute asynchronously, as a defense against timing attacks.</span>
</span><span class='line'>
</span><span class='line'><span class='sd'>    The responder decorator should be applied after (above) this decorator::</span>
</span><span class='line'>
</span><span class='line'><span class='sd'>        @SomeCommand.responder</span>
</span><span class='line'><span class='sd'>        @_immediateResponder</span>
</span><span class='line'><span class='sd'>        def responder(...):</span>
</span><span class='line'><span class='sd'>            ....</span>
</span><span class='line'>
</span><span class='line'><span class='sd'>    This should be timing attack resistant since it is unconditional: the</span>
</span><span class='line'><span class='sd'>    the AMP response is returned immediately, and the real responder is</span>
</span><span class='line'><span class='sd'>    scheduled to run at the next chance the reactor has to do so.</span>
</span><span class='line'>
</span><span class='line'><span class='sd'>    This only works with AMP commands with empty responses. That&#39;s probably a</span>
</span><span class='line'><span class='sd'>    good idea anyway: almost all information you could add to the response</span>
</span><span class='line'><span class='sd'>    is liable to introduce a timing attack vulnerability.</span>
</span><span class='line'>
</span><span class='line'><span class='sd'>    Since this precludes your ability to communicate success or failure to</span>
</span><span class='line'><span class='sd'>    the caller, the decorated function should return quite quickly (or, if it</span>
</span><span class='line'><span class='sd'>    can&#39;t, that should be clearly documented). Otherwise, you may end up in a</span>
</span><span class='line'><span class='sd'>    a race condition, where the caller assumes the operation has completed,</span>
</span><span class='line'><span class='sd'>    but it is in progress or hasn&#39;t started yet.</span>
</span><span class='line'>
</span><span class='line'><span class='sd'>    The original responder function is available on the decorated function as</span>
</span><span class='line'><span class='sd'>    the ``responderFunction`` attribute.</span>
</span><span class='line'><span class='sd'>    &quot;&quot;&quot;</span>
</span><span class='line'>    <span class='nd'>@functools.wraps</span><span class='p'>(</span><span class='n'>f</span><span class='p'>)</span>
</span><span class='line'>    <span class='k'>def</span> <span class='nf'>wrapped</span><span class='p'>(</span><span class='bp'>self</span><span class='p'>,</span> <span class='o'>*</span><span class='n'>args</span><span class='p'>,</span> <span class='o'>**</span><span class='n'>kwargs</span><span class='p'>):</span>
</span><span class='line'>        <span class='n'>reactor</span><span class='o'>.</span><span class='n'>callLater</span><span class='p'>(</span><span class='mi'>0</span><span class='p'>,</span> <span class='n'>f</span><span class='p'>,</span> <span class='bp'>self</span><span class='p'>,</span> <span class='o'>*</span><span class='n'>args</span><span class='p'>,</span> <span class='o'>**</span><span class='n'>kwargs</span><span class='p'>)</span>
</span><span class='line'>        <span class='k'>return</span> <span class='p'>{}</span>
</span><span class='line'>
</span><span class='line'>    <span class='n'>wrapped</span><span class='o'>.</span><span class='n'>responderFunction</span> <span class='o'>=</span> <span class='n'>f</span>
</span><span class='line'>    <span class='k'>return</span> <span class='n'>wrapped</span>
</span></code></pre></td></tr></table></div></figure>
<p>When I get an incoming RPC call, the function doing the actual work is scheduled to run at the next reactor iteration. Then, an empty response is returned. All of this happens in amortized constant time, and independent of any secrets. As a result, it can’t really leak much about them.</p>

<h2 id="an_abstraction_too_high">An abstraction too high</h2>

<p>The above was an effective response to a proof-of-concept timing attack exploit. Unfortunately, that doesn’t mean you’ve fixed every timing attack.</p>

<p>In particular, this example is a few layers of abstraction removed from the grit of real-world I/O. Just because I returned <code>{}</code> (an empty response) immediately, doesn’t mean the underlying IO happens immediately.</p>

<p>In particular, the write output latency could be coerced to depend on the computation time, because the function passed to it could be executed before the <code>write</code>. If that happens, and the time it takes is dependant on some secret, delaying the write, the latency on the attacker’s side could be used to measure the work done.</p>

<p>I have not yet been able to turn the above into a working exploit.</p>

<p>There are a number of ways this could be mitigated. Since there’s no working exploit, it’s unclear if this mitigation would render a timing attack infeasible.</p>

<p>One way I’ve considered to mitigate this is to limit the time that the reactor is blocked. In my concrete example, this was fortunately already the case, since one of the first things it did was defer to a thread that released the GIL (to compute the key from the password using <code>scrypt</code>). Alternatively, if you’re doing this for Python code, you could write your function cooperatively.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Moving to Octopress on Github Pages]]></title>
    <link href="http://www.lvh.io/blog/2013/01/28/moving-to-octopress-on-github-pages/"/>
    <updated>2013-01-28T10:58:00+01:00</updated>
    <id>http://www.lvh.io/blog/2013/01/28/moving-to-octopress-on-github-pages</id>
    <content type="html"><![CDATA[
<p>Long overdue, I’m told.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Designing a REST API: Logging In]]></title>
    <link href="http://www.lvh.io/blog/2011/11/27/designing-a-rest-api-logging-in/"/>
    <updated>2011-11-27T00:00:00+01:00</updated>
    <id>http://www.lvh.io/blog/2011/11/27/designing-a-rest-api-logging-in</id>
    <content type="html"><![CDATA[<div>Hey. As many of you probably know, I&#8217;m building a business, and that business involves a REST API being consumed by browsers (for now).</div>
<p />
<div>The problem I&#8217;m hitting is registration and logging in. It just doesn&#8217;t seem to be a problem that fits REST very well &#8211; maybe I&#8217;m thinking too much about services and not enough about resources, so I&#8217;m writing this blog posts to get my thoughts in order and hopefully get some useful feedback.</div>
<p />
<div>This post is about user registration and login, and how they&#8217;re hard to fit into REST.</div>
<p />
<div>Context: users are uniquely identified by a user id, which is a random string of sufficient size. These ids are immutable and uniquely refer to this user from registration until forever. User emails are also unique, but they can change, so they are not a good way to refer to a user. Users register and log in using email and password.</div>
<p />
<div><strong><span style="font-size: medium;">Option 1: separate authentication endpoint</span></strong></div>
<p />
<div>The idea here is that there are two things:</div>
<div>
<ul>
<li>the REST API, which authenticated things talk to</li>
<li>the authentication endpoint, where unauthenticated things go to become authenticated</li>
</ul>
The downside is that there are two things. One of them speaks REST, and the other speaks gnarly ad-hoc RPC or maybe JSON-RPC or something.</div>
<p />
<div>The upside is that the REST API only needs to understand one kind of token.</div>
<p />
<div><span style="font-size: medium;"><strong>Option 2: everything in REST</strong></span></div>
<p />
<blockquote class="gmail_quote" style="margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0.8ex; border-left-width: 1px; border-left-color: #cccccc; border-left-style: solid; padding-left: 1ex;">Special cases aren&#8217;t special enough to break the rules.</blockquote>
<blockquote class="gmail_quote" style="margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0.8ex; border-left-width: 1px; border-left-color: #cccccc; border-left-style: solid; padding-left: 1ex;">&#8211; Zen of Python</blockquote>
<p />
<div>The advantage is that there is one canonical source for everything. Everything including access grants (which should be nice for OAuth later). You can use the REST API to perform any action, see anything in the system&#8230;</div>
<p />
<div>The downsides:</div>
<div>
<ul>
<li>the REST API has to understand more than one kind of authentication. This also might make it a bit uglier to interoperate with OAuth later.</li>
<li>Logging in takes too many round trips. First I have to query <span style="font-family: courier new,monospace;">users/?email={EMAIL}</span><span style="font-family: arial,helvetica,sans-serif;">&nbsp;to go from e-mail address to user id. Then, I have to POST to users/accessGrants &#8211; which is if I&#8217;m allowed to guess the URL, which I really shouldn&#8217;t, I should GET users/ first (HATEOAS and all that &#8211; but I&#8217;m willing to ignore that for now). All of this happens over HTTPS with HTTP Basic auth. TLS handshakes are slow, and verifying securely stored passwords is even slower.</span></li>
</ul>
</div>
<p />
<div><strong><span style="font-size: medium;">Option 2b: everything in REST, with shortcuts</span></strong></div>
<blockquote class="gmail_quote" style="margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0.8ex; border-left-width: 1px; border-left-color: #cccccc; border-left-style: solid; padding-left: 1ex;">Although practicality beats purity.</blockquote>
<blockquote class="gmail_quote" style="margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0.8ex; border-left-width: 1px; border-left-color: #cccccc; border-left-style: solid; padding-left: 1ex;">&#8211; Zen of Python&nbsp;</blockquote>
<div>&#8230; but, unfortunately, also:</div>
<blockquote class="gmail_quote" style="margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0.8ex; border-left-width: 1px; border-left-color: #cccccc; border-left-style: solid; padding-left: 1ex;">
<div>There should be one&#8211; and preferably only one &#8211;obvious way to do it.</div>
</blockquote>
<blockquote class="gmail_quote" style="margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0.8ex; border-left-width: 1px; border-left-color: #cccccc; border-left-style: solid; padding-left: 1ex;">&#8211; Zen of Python&nbsp;</blockquote>
<p />
<div>The upsides are the same as for the REST API, except we get rid of the downside that logging in takes too many round trips, because there&#8217;s a shortcut for that.</div>
<p />
<div>That shortcut would be something that speaks some kind of ad-hoccy RPC, or possibly JSON-RPC. One of the exported methods/procedures would be &#8220;getGrant&#8221;, which takes a username and password and returns the key. These endpoints talk to the same database behind the scenes. Killer feature: one round trip.</div>
<p />
<div>Downside is that the API should probably still be able to take user credentials, since this is is a shortcut&#8230;.</div>
<p />
<div>Yes, I know OAuth exists. For now, we have no interest in opening this API up yet. We&#8217;ll do that as soon as we have a platform worth caring about, an API that doesn&#8217;t change every three seconds, and a security expert that&#8217;s reviewed it.</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[I Don't Understand REST Pagination]]></title>
    <link href="http://www.lvh.io/blog/2011/05/12/i-don-t-understand-rest-pagination/"/>
    <updated>2011-05-12T00:00:00+02:00</updated>
    <id>http://www.lvh.io/blog/2011/05/12/i-don-t-understand-rest-pagination</id>
    <content type="html"><![CDATA[Hey.<p /><br />So, in <a href="https://github.com/lvh/txyoga">txYoga</a>, in implemented pagination in terms of query parameters to a collection. If you want to access the range of elements [100, 110), you would say: <span style="font-family: courier new,monospace;"><a href="http://whatever/collection?start=100;stop=110">http://whatever/collection?start=100;stop=110</a></span>. The feature here is that pages give you the link to the next and previous page. The response (JSON) looks something like <span style="font-family: courier new,monospace;">{&quot;results&quot;: [&#8230;], &quot;next&quot;: nextURL, &quot;prev&quot;: prevURL}</span>. That way, you pretty much just have to follow URLs to walk down the collection as a doubly  linked list of pages. The supposed feature is that I can change how my pages work, and users hopefully won&#39;t notice, since they shouldn&#39;t be building their own URLs anyway.<p /> Now, at the same time, I&#39;m looking at <a href="http://dojotoolkit.org/reference-guide/dojo/store/JsonRest.html">dojo&#39;s JsonRest API</a>. It&#39;s suggesting that I use the Range and Content-Range headers for pagination support. It also has a single JSON array as a response (so, [{&#8230;}, &#8230;]) instead of my JSON object. I started RFC diving and hey look, they&#39;re right, HTTP understands <a href="http://www.w3.org/Protocols/rfc2616/rfc2616-sec3.html#sec3.12">ranges with arbitrary units</a>. So, are my URLs wrong? Are people supposed to conjure Range URLs themselves? Why are these darned ranges inclusive? Another problem is that the specification doesn&#39;t really seem to support non-numeric ranges, whereas to txYoga, that&#39;s not really a problem as long as the underlying collection understands it.<p /> Isn&#39;t REST supposed to be hypertext-driven? Aren&#39;t people basically supposed to never construct URLs, and rely on me to provide them to them? Where am I supposed to put those URLs? Yaaargh.<p /> <br />cheers<div>lvh</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Crowdsourcing Opinions on a REST API: POST, PUT or Both?]]></title>
    <link href="http://www.lvh.io/blog/2011/05/06/crowdsourcing-opinions-on-a-rest-api-post-put-or-both-/"/>
    <updated>2011-05-06T00:00:00+02:00</updated>
    <id>http://www.lvh.io/blog/2011/05/06/crowdsourcing-opinions-on-a-rest-api-post-put-or-both-</id>
    <content type="html"><![CDATA[As some of you undoubtedly know, I&#39;m writing a thing called txYoga, which is a REST framework for Twisted.<p />The fundamental operations in this post are CRUD:<br /><ol><li>Creating elements</li><li>Retrieving them</li> <li>Updating them</li><li>Deleting them</li></ol>Now, retrieving is obvious: send a GET request to the element. Getting rid of them is too: same thing, but a DELETE. Updates are done using PUT to the element. Creating elements, though, is a bit more ambiguous:<br /> <ol><li>If the client knows the complete path to the element (so, particularly the final part of the new element&#39;s URI), it PUTs to that URI (for which there is currently no element).</li><li>If the client doesn&#39;t know or care, it POSTs to the collection. The collection creates the element, and probably returns the URL under which the new element is available.<br /> </li></ol>One of the fundamental differences between POST and PUT is that PUT is idempotent, but POST is not. If you send me the same PUT request once, twice or ten times, you&#39;ll end up with the same state. POSTing to the collection might work once (or pretty much indefinitely, if you&#39;re producing objects with an UUID identifier for example).<p /> This is because in txYoga, each element has exactly one identifying attribute (which is the thing that&#39;s used to access the element). That&#39;s what makes PUT feels so awkward: what you&#39;re putting contains the information to decide what the name of the object is (since it has to have the identifying attribute), but the object doesn&#39;t know what name it&#39;s going to be put under (since that name only exists after the object is created), so you have to repeat yourself. With POST, you don&#39;t really care.<p /> Additionally, you&#39;d be using the same thing for updating and creating new elements, which I guess sort-of makes sense, but reminds me of Perl&#39;s autovivification and not in a good way.<p />The question is: should I support both PUT and POST for creating elements? On the one hand, There should be one&#8211; and preferably only one &#8211;obvious way to do it. On the other, this is what REST pretty much does &#8211; and practicality beats purity (although this isn&#39;t very practical for me&#8230;).
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Reflections on Stories From (Disgruntled) Launchpad Users]]></title>
    <link href="http://www.lvh.io/blog/2011/03/09/reflections-on-stories-from-disgruntled-launchpad-users/"/>
    <updated>2011-03-09T00:00:00+01:00</updated>
    <id>http://www.lvh.io/blog/2011/03/09/reflections-on-stories-from-disgruntled-launchpad-users</id>
    <content type="html"><![CDATA[Hello again :-)<p /><br />I tweeted something. I&#39;m quite proud of it. It&#39;s exactly 140 characters, and it captures the essence of the last few days&#39; worth of articles quite well. Obviously it makes concessions to accuracy for reasons of brevity, but here goes anyway:<p /> <div style="margin-left: 40px;">It seems to me Github people use Github as a coping mechanism for git, and Launchpad people use Bazaar and a coping mechanism for Launchpad.</div><br />That explains virtually all of the feedback and workflow I&#39;ve received. It seems Github users use git as a tool to get code into Github as quickly as possible, so magic and sprinkles can be added to it. That means the Github people have done an excellent job. It&#39;s managed to create an environment where you have awesome features like truly polished pull requests and a great code browser that lets you peek into someone else&#39;s repository without you having to worry about adding a remote, fetching objects, removing a remote&#8230;<p /> Github tries to minimize your exposure to git &#8211; <a href="http://chriswanstrath.com/hub/">hub</a> even more so (with hub, clones and pulls look like they do with bzr for me. Huge win.). Even without having to call git&#39;s UX bad, that makes (business) sense: the Github people aren&#39;t the git people so they want you in their service as much as possible. And man, have they succeeded.<p /> On the other side of that argument, there&#39;s Launchpad and Bazaar. Most of the discussions about Launchpad&#39;s UI warts (and, keeping in mind my last article, some of them are just a question of catering to a different audience but some of them really are simply faults) go something like this:<br /> <div style="margin-left: 40px;"><b>unhappy user:</b> Hey lvh, take a look at $BOGUS_UI_CHOICE. Come on, you have to admit, that just sucks.<br /><b>lvh</b>: Huh. You&#39;re right &#8211; that is pretty bad. I just never noticed because I use $BZR_INVOCATION to get to that information.<br /> </div><br />Case in point: merge proposals. Apparently they had an in-page diff. I had no idea.<p />Github users use Github to do things. Launchpad users use Launchpad as branch storage + metadata (bug tracker, merge proposals, primarily) so they can convince bzr to do things. When Github users go to Launchpad, perhaps without truly trying to use it, they see the prospect of using something like Github but worse. When Launchpad users go to Github, they see the prospect of getting to use git for everything instead of bzr. (And, let&#39;s be honest &#8211; if you&#39;re diffing between remotes all day, Github is more pleasant than plain git, and bzr is too.)<p /> cheers<div>lvh</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[On Sysadmins, Programmers, and Reconciliation (a Response to Zed Shaw's Post)]]></title>
    <link href="http://www.lvh.io/blog/2011/03/08/on-sysadmins-programmers-and-reconciliation-a-response-to-zed-shaw-s-post-/"/>
    <updated>2011-03-08T00:00:00+01:00</updated>
    <id>http://www.lvh.io/blog/2011/03/08/on-sysadmins-programmers-and-reconciliation-a-response-to-zed-shaw-s-post-</id>
    <content type="html"><![CDATA[Zed Shaw posted <a href="http://sheddingbikes.com/posts/1299555462.html">a response</a> to <a href="http://b.lvh.cc/why-do-people-hate-launchpad-so-much">my article on why people hate Launchpad</a>. Apart from causing the number of readers to skyrocket by an order of magnitude, it&#39;s given me some new perspective on the problem. As always, I love feedback, especially if people agree with things I say ;-)<p /> Assuming Zed&#39;s right (and I think he&#39;s at the very least got a point), <a href="http://b.lvh.cc/a-compiled-list-of-launchpads-perceived-flaws">my previous list of grievances</a> splits up into two things:<br /> <ol> <li>Things that make Launchpad more like Github. In Zed&#39;s terminology, make Launchpad less of a sysadmin place and more of a programmer place. Following Zed&#39;s conclusion, these are bad changes.<br /></li><li>Things that make everyone&#39;s life easier and aren&#39;t necessarily about one group versus the other. As the contrapositive to Zed&#39;s conclusion, they are good changes.<br /> </li></ol>Now, I think at least some of the UI changes from that list are in that last group. Particularly the code browser UI issues (and they are legion &#8211; Loggerhead is on occasion hard to like) are something I don&#39;t really see how anyone could object to. Concrete examples are:<br /> <ul><li>Renaming &quot;View branch content&quot; to &quot;View code&quot;. &quot;Code&quot; is a word programmers scan for. To quote Zed&#39;s article: code, code, code. Contrary to popular belief you can actually access trunk&#39;s code with a single click from the project&#39;s front page! It&#39;s just cleverly hidden.<br /> </li><li>Merging the branch and branch content pages, embedding Loggerhead in the page like Github&#39;s file browser, instead of making it a separate page. Sysadminny types probably wouldn&#39;t ever have looked at that page in the first place.</li> <li>Removing dead project features (like translations, blueprints, answers) for J. Random User</li></ul>There are, of course, also ideas that would piss off the syadminny group, like moving series around or putting a Github style code browser on the overview page. (Probably explains why I dislike that last feature.)<p /> But yeah: if you fixed every single point in that list of perceived flaws, my in-brain mockup of what Launchpad 2.0 would look like would still decidedly be Launchpad and not Github: which is probably what Zed is talking about. And, like he said, that doesn&#39;t actually have to be problem.<p /> I agree that both Github and Launchpad would be very hard-pressed to transform into something everyone likes, but the &quot;why&quot; of that wasn&#39;t quite clear enough in my head yet for me to write a blog post about it (my posts are bad enough when I&#39;m convinced I do know what I want to say). Zed&#39;s article helped quite a bit there.<p /> The difference is I have no idea what this third system that caters to both in the same place would look like yet. Zed probably has a better idea of what he&#39;s talking about than I do.<p />My idea is different. It&#39;s probably a bit worse, since you&#39;d have N places where code live instead of 1, but at least in the short run it seems like less effort to end up with a working thing. The idea goes like this: if Github and Launchpad are really different beasts catering to different beasts, maybe we shouldn&#39;t try to make them be the same, and instead let them cooperate. This is why I think (well, hope) the idea of <a href="http://b.lvh.cc/bridging-the-gap-between-launchpad-and-github">bridging Launchpad and Github</a> &#8211; having them play nicely together in the same sandbox instead of the current situation we&#39;re they&#39;re direct competitors &#8211; may have some value to it.<p /> I&#39;d really like some feedback on Github fans on that. I <i>know</i> Launchpad people are going to like it since they can pretty much just use Launchpad and don&#39;t have to care Github exists. I&#39;m hoping people don&#39;t find Launchpad so revolting that using its bug tracker and merge proposals (as cited in that article I linked, features at least as good on Launchpad as on Github) becomes a contribution blocker.<p /> cheers<br />lvh
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Bridging the Gap Between Launchpad and Github]]></title>
    <link href="http://www.lvh.io/blog/2011/03/06/bridging-the-gap-between-launchpad-and-github/"/>
    <updated>2011-03-06T00:00:00+01:00</updated>
    <id>http://www.lvh.io/blog/2011/03/06/bridging-the-gap-between-launchpad-and-github</id>
    <content type="html"><![CDATA[Hey.<p /><br />Ever the diplomat, I&#39;ve been trying to figure out a way to use Launchpad yet keeping the people that dislike it happy.<p />It is based on two premises. If you disagree with them, you may as well stop reading now. (or, even better: tell me why)<br /> <ul><li>Launchpad&#39;s bug tracker is preferable, or at least equal, to Github Issues.</li><li>Launchpad&#39;s merge proposals are identical to Github Pull Request 2.0&#39;s, with the exception of bug tracker integration.</li> </ul>First of all, the project uses Launchpad as a bug tracker, and Launchpad merge proposals as the mandatory code review for getting code into trunk. Launchpad trunk is constantly mirrored into a Github repository.<p />  Launchpad users that want to develop the project pretend Github doesn&#39;t exist.<p />Github users that want to develop the project pretend Launchpad doesn&#39;t exist. They just fork the repository and make some changes, as they normally would. Once they want to get some code into trunk, they file a pull request, which is where the magic starts.<p /> A bot creates an alternative merge proposal equivalent to the pull request. There are two options for doing that:<br /><ul><li>Grabbing the pull request diff</li><li>Using bzr-git to import the branch into git</li></ul> (The latter is preferable because it preserves commit structure. The former is probably easier to implement and less hairy to implement/maintain due to impedance mismatches.)<p />Either way, a new branch is created with the same name as the Github branch. Ideally, the merge proposal is linked to the appropriate bug. That means the branch should contain information about the bug it relates to (possibly in the name, eg 54321-fixQuantumTransmogrifier), since, as far as I know, git has no equivalent to bzr commit&#39;s &#8211;fixes. The pull request gets a link to the merge proposal. All review-related work happens in Launchpad, not Github. Based on the second premise, this is acceptable.<p /> The obvious problem here is that Github users can&#39;t really monitor what&#39;s going on in terms of development in Launchpadland and vice-versa. A solution may be to push more branches, but I dislike doing that. Perhaps using their respective APIs, the data can be syndicated into a common source. Ideas welcome.<p /> cheers<div>lvh</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A Compiled List of Launchpad's Perceived Flaws]]></title>
    <link href="http://www.lvh.io/blog/2011/03/06/a-compiled-list-of-launchpad-s-perceived-flaws/"/>
    <updated>2011-03-06T00:00:00+01:00</updated>
    <id>http://www.lvh.io/blog/2011/03/06/a-compiled-list-of-launchpad-s-perceived-flaws</id>
    <content type="html"><![CDATA[<p>(Note: just because I say &#8220;perceived&#8221; flaws doesn&#8217;t mean I don&#8217;t agree they are. It&#8217;s just a way to encourage feedback from people who disagree.)<p />I&#8217;ve compiled the responses I&#8217;ve received so far to <a href="http://b.lvh.cc/why-do-people-hate-launchpad-so-much" target="_blank">my previous article about Launchpad</a>. This is intended as constructive criticism and hopefully stuff that can be used to build a better Launchpad.<p /> I&#8217;d like to thank everyone who bothered to have a <a href="http://b.lvh.cc/religious-wars-considered-harmful-considered">sensible, adult discussion</a> about Launchpad with me. I very much appreciate your feedback, even the rants. The Launchpad people are also expressed interest in this previously unreceived feedback (which makes sense, I guess). There certainly were a lot of you! If it ends up making Launchpad a nicer place for everyone maybe it&#8217;s worth the time it took, though.<p /> The vast majority of complaints I&#8217;ve seen are about Launchpad&#8217;s interface.&nbsp; People perceive the Launchpad interface as hard to use and anything but obvious. They particularly feel there&#8217;s just too much noise, making useful features hard to find.<p /> I tried to distill stuff that smells like it&#8217;s easy to fix to me. It didn&#8217;t always work, of course. Some problems (primarily about Loggerhead) require non-trivial amounts of work.<p />Here are some concrete examples:</p>
<ol>
<li>As a user, I don&#8217;t care that a project doesn&#8217;t use Launchpad for translations, but it takes up the spot of a primary feature in the main menu and the Get Involved box. It should only be shown to the Maintainer (a single user or a group). This also counts for&nbsp; Blueprints and Answers, except it&#8217;s less obvious what they mean to people, apparently. Most projects really only need Overview, Code and Bugs (in fact, Github and Bitbucket do away with the entire Overview tab, too &#8211; but that&#8217;s not universally seen as a requirement for a usable thing).</li>
<li>Latest reported bugs, latest questions and the FAQ box on the landing page are considered unnecessary noise: it&#8217;s duplicated on the respective specific pages, and the people who actually need that kind of notification probably should get e-mails anyway.</li>
<li>Announcements on the other hand are a far more important feature, but they&#8217;re tucked away: on the Bazaar&#8217;s Launchpad Overview page, I have to scroll down to find it. Perhaps they should have a more prominent position on the page.</li>
<li>Downloads are important enough that they probably warrant a separate page. The Overview page&#8217;s Packages in Distributions pages can be moved there, too, further decluttering the Overview page.</li>
<li>A lot of people don&#8217;t understand Blueprints or consider it a misfeature. Fixing the first point would obviously alleviate that since it&#8217;d be opt-in.</li>
<li>As a user, I can&#8217;t figure out how to browse the code. &#8220;View branch content&#8221; ought to be called &#8220;View code&#8221;, or something &#8211; it makes sense to a Bazaar/Launchpad user but not to J. Random Contributor.</li>
<li>People really like Github&#8217;s Readme Driven Development. Perhaps the overview could be grabbed from the development focus&#8217; README file? Admittedly some README&#8217;s may be too large for this to work well with the current landing page.</li>
<li>Subscribe to bug mail is a primary feature on the project landing page, even above the Get Involved box. This doesn&#8217;t make sense: that&#8217;s a Bugs specific feature, and the Bugs page has an identical feature already. It could just be removed without loss of functionality.</li>
<li>Series and milestones are a code feature: I don&#8217;t particularly care about them on the overview page, and they would probably be better off on the code page. Preferably after the branches or at least foldable, since it does take up quite a bit of screen real estate. In order to parse it and turn it into useful information, you probably need to be more than a little involved in the project already. The idea is that not sufficiently many users care to warrant such a prominent place on the landing page.</li>
<li>Loggerhead&#8217;s date format is hard to parse. Github and Bitbucket use relative, human-readable timedeltas, except for dates sufficiently far away (where they use a plain date). You could still make the real date accessable on mouseover if people wnat that feature.</li>
<li>Loggerhead is very poorly integrated with the rest of Launchpad: it feels like a tacked on feature. Compare to Github and Bitbucket where code viewing is an integral part of the user experience.</li>
<li>Somewhat conjoined with the previous point: there&#8217;s a separate page for a branch and the branch content and that confuses people. Perhaps they could be integrated without overloading branch pages. (One particularly important feature is merge proposals, but they&#8217;re accessible from the Code page).</li>
<li>People are unhappy with the lack of progress on Loggerhead. I feel kind of bad about this point since it makes me sound like I&#8217;m calling people lazy bums, but journalistic integrity demands I report it. I had <a href="https://bugs.launchpad.net/loggerhead/+bug/569358%20">quite</a> <a href="https://bugs.launchpad.net/loggerhead/+bug/569355">a few</a> bugs listed as examples. I don&#8217;t know if these are unique or illustrations of a more general problem.</li>
<li>Although merge proposals are used for code review, people are confused by the Code page saying &#8220;code review&#8221; when it means &#8220;merge proposals&#8221;. It would be nice if everything said merge proposals. Or is the point here that Launchpad might integrate with other code review tools?</li>
<li>Some people can&#8217;t use the e-mail interface <a href="https://bugs.launchpad.net/bugs/643224">because the DKIM whitelist is hardcoded</a>.</li>
</ol>
<p><br />To be continued.<p />cheers<br />lvh</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Why Do People Hate Launchpad So Much?]]></title>
    <link href="http://www.lvh.io/blog/2011/03/05/why-do-people-hate-launchpad-so-much-/"/>
    <updated>2011-03-05T00:00:00+01:00</updated>
    <id>http://www.lvh.io/blog/2011/03/05/why-do-people-hate-launchpad-so-much-</id>
    <content type="html"><![CDATA[Following a discussing on Convore recently, I noticed some people (names withheld to protect the guilty &#8211; I&#39;m sure they will speak up if they feel like it) strongly dislike Launchpad. Apparently they dislike it so much they would rather use a different project if they find something that uses it.<p /> I don&#39;t get it.<p />First off, lI&#39;m not trying to make this a git vs hg vs bzr vs whatever discussion, except perhaps to the extent that those tools shape their respective hosting system. Not that I think those discussions have to devolve into religious wars (<a href="http://b.lvh.cc/religious-wars-considered-harmful-considered">a subject on which I have blogged recently</a>), it&#39;s just that I&#39;d like to limit the scope so we end with a bunch of things that can actually be improved.<p /> My main problem with <a href="https://github.com/">the 500lb gorilla in the room</a> is its issue tracker. I know, it&#39;s a simple feature tacked on later, and all in all the ability to link to branches and revisions and to be able to close tickets from commit messages ain&#39;t so bad.<p /> One particular unfortunate choice is that they decided to make pull requests issue tracker artifacts. I&#39;m convinced it should be an attachment to one, instead. Pull requests are about merging code. There must be a reason to do that &#8211; that reason is a ticket. That means if you use pull requests as a mechanism for code review (which they seem to be marketed as), ergo having all code be added using them, all changes to trunk have at least two issue tracker artifacts: the ticket describing the change, and the pull request carrying the code that does it. I think that&#39;s a bit silly. Pull requests hence often become somewhat of a ticket in their own right, which works well for one-time contributions which are typically limited in scope, but it seems this results in an inconsistent workflow which is a bit more annoying for things that actually do require a ticket.<p /> Launchpad&#39;s issue tracker, on the other hand, is one I particularly like.<p />It&#39;s unique in the sense that it lets you track the state of bugs in different parts of downstream. Additionally, bugs aren&#39;t unique to a project &#8211; allowing people from different groups to collaborate on the same issue. It lets me assign bugs to a person: a feature I sorely miss in Github. The equivalent of Github Issue&#39;s voting feature is just a &quot;this affects me&quot; link: similar to Google Code&#39;s starring idea. The goal is always the same: measure the importance of a bug without getting the noise of a million &quot;me, too&quot; messages. (Github and Launchpad&#39;s way of doing it seems more effective, though.)<p /> Launchpad&#39;s alternative to pull requests, called merge proposals, are quite similar to Github&#39;s pull requests 2.0. The main difference is the bug tracker interaction: like I&#39;ve described above, they <i>attach</i> to issues, instead of being them themselves.<p /> A complain I often hear yet don&#39;t quite grok is the apparent difficulty of getting to code. Personally, I don&#39;t quite see the problem. The main branch (lp:projectname) and its contents are one click away from the front page. All of the branches of a project (from everyone! not just the project leads), are visible with a single click from the project front page, under the &quot;Code&quot; menu. I must admit I rarely use that web UI: instead, I just bzr co lp:projectname if I want to take a look.<p /> The contributor story is also fairly pleasant, in my opinion. I don&#39;t even need to fork anything (at least not explicitly): just get the branch, make some changes, push them to lp:~lvh/projectname/mybranch and done. That magic syntax isn&#39;t Launchpad-specific: that&#39;s called <a href="https://code.launchpad.net/bzr-bookmarks">a bookmark</a>, and you can just as well have your own if you don&#39;t use Launchpad.<p /> So what exactly is the problem? I&#39;m planning on moving a project from Fossil to something else at Pycon &#8211; but if everyone hates it so much, I&#39;m willing to reconsider. For example: I&#39;d use Github if I can find a useful issue tracker to go with it. I&#39;d use bitbucket if there&#39;s some reasonable way to have in-repo pull requests (like Github pull requests 2.0 or Launchpad merge proposals).
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Religious Wars Considered Harmful Considered Harmful]]></title>
    <link href="http://www.lvh.io/blog/2011/03/05/religious-wars-considered-harmful-considered-harmful/"/>
    <updated>2011-03-05T00:00:00+01:00</updated>
    <id>http://www.lvh.io/blog/2011/03/05/religious-wars-considered-harmful-considered-harmful</id>
    <content type="html"><![CDATA[Hey.<p /><br />Can we stop avoiding subjects because we&#39;ve elevated them to the state of personal opinion? Especially since &quot;personal opinion&quot; usually ends up meaning &quot;dogma&quot;, and is quite often used as an excuse to cover up ignorance.<p /> The usual suspects here are of course:<br /><ul><li>vim versus emacs versus whatever</li><li>git versus mercurial versus bazaar versus whatever</li><li>twisted versus gevent versus eventlet versus tornado versus whatever</li> <li>django versus pyramid versus web2py versus web.py versus cherrypy versus whatever<br /></li></ul>Here&#39;s why. Not every discussion about them has to devolve into a full-blown flame war. Yes, there are trolls. Yes, there are clueless fan-boys who&#39;ve drunk one glass too many of the delicious Kool-Aid. We have those pretty much everywhere else, too, though: and we just ignore them. But we&#39;re not trolls &#8211; we&#39;re reasonable adults with different favorite tools. Perhaps that&#39;s based on extensive experience. Perhaps it isn&#39;t. Perhaps it&#39;s based on stuff that&#39;s not even true anymore. Can&#39;t we talk about them as one reasonable adult to another? Preferably without resulting in name calling and blatant demagogy.<p /> Dismissing discussions a priori effectively means you&#39;ve decided, up front, that they&#39;re going to have a net negative outcome. At best, that&#39;s insulting to the people you&#39;d be discussing with. At worst, it&#39;s a monumental display of arrogance, since you&#39;ve just decided that there is nothing that can be learned from people who have done things differently.<p /> I&#39;m not talking about people who mindlessly promote their favorite version control system or editor or library, without having given the alternatives the light of day. They&#39;re annoying in their own right, but they&#39;re nothing compared to the people who then proceed to trash-talk the alternatives without having any real arguments. Like something someone smarter than myself said: <a href="https://twitter.com/#%21/jacobian/status/18369419788951552">&quot;if you promote your project by dissing the competition, I&#39;ll assume that your project sucks or you&#39;re a dick. Either way I won&#39;t use it.&quot;</a> &#8211; except it&#39;s not even their project.<p /> If you don&#39;t know what a mark ring or a kill ring is, any disparaging comment you make about Emacs is probably worth a troll stamp, sorry. If you haven&#39;t used anything but git, I&#39;m not particularly interested that you think everything that isn&#39;t git is dumb. If you didn&#39;t manage to get through the finger tutorial and you&#39;ve never used any of the alternatives either, I don&#39;t really care if you think Twisted is complicated. Quite frankly, you don&#39;t know what you&#39;re talking about. Your braindead statements don&#39;t contribute to anything but my blood pressure.<p /> I&#39;ve tried to have sensible discussions countless times, and when I succeeded, it ended up being perfectly civil <i>and</i> showing someone how maybe not everything the enemy is doing is so bad. Perhaps they have ideas worth stealing. Perhaps we can stop worrying about what separates us, silence the trolls like we do everywhere else, and focus on what we have in common.<p /> cheers<br />lvh
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Pycon US Talk]]></title>
    <link href="http://www.lvh.io/blog/2010/10/13/pycon-us-talk/"/>
    <updated>2010-10-13T00:00:00+02:00</updated>
    <id>http://www.lvh.io/blog/2010/10/13/pycon-us-talk</id>
    <content type="html"><![CDATA[Finances permitting, I will attend Pycon US 2011. I will also try to give a talk about most of the meat and potatoes on this blog.<p /><div>What do you think should be included? What do you think shouldn&#39;t be?</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Cautious Deployment for Continuous Availability]]></title>
    <link href="http://www.lvh.io/blog/2010/10/04/cautious-deployment-for-continuous-availability/"/>
    <updated>2010-10-04T00:00:00+02:00</updated>
    <id>http://www.lvh.io/blog/2010/10/04/cautious-deployment-for-continuous-availability</id>
    <content type="html"><![CDATA[<div>In <a href="http://lvh.posterous.com/designing-a-continuous-deployment-system-caut">my last post</a>, I talked about cautious deployment as a technique for recovering from botched deployments. Cautious deployment&nbsp;also solves a second problem by helping you get continuous availability.</div>
<p />
<div>In the article about cautious deployment, I had the following graph for hypothetical, optimistic deployment:</div>
<div>[[posterous-content:L2vALkn09tFOvqjIkPGw]]</div>
<p />
<div>Obviously, that&#8217;s a bit simplistic. It would be correct, if all your servers decide to restart the service in a perfectly synchronized fashion, and all of your servers manage do that operation in precisely identical amounts of time, and no interdependencies between your services.</div>
<p />
<div>Typically: none of those things are true. starting services is a stochastic process and you really don&#8217;t quite know how long it&#8217;ll take. Stuff depends on each other all the time. Hence, the graph is more likely to look something like this:</div>
<p />
<div>[[posterous-content:67uOLIMpCLyTivUYZ5MS]]</div>
<div>Of course, it&#8217;s occasionally way worse than this. Your users generally don&#8217;t know nor care that you&#8217;re upgrading, so those few early starters get to deal with a disproportionately high load. That could happen up to the point where watchdogs mistakenly believe the process has just crashed. That watchdog then orders for that process to be restarted, which of course only makes it worse for all of the other processes still up.</div>
<p />
<div>(If you&#8217;re thinking &#8220;Oh come on. It&#8217;s nowhere near that bad&#8221; &#8211; how do you know? Did you measure that? For some people, it definitely is.)</div>
<p />
<div>This problem is often overlooked, because there&#8217;s tons of ways of missing it completely (mostly because&nbsp;statistics is hard).</div>
<div><ol>
<li>Not even bothering to analyze (unfortunately the most common)</li>
<li>Not recognizing the worst case</li>
<li>Normal distribution not being a good fit</li>
<li>Failure to recognize the weakest link</li>
</ol></div>
<div>Unfortunately, most of the people fall in group one. Come on guys, we can all do better than this. If there&#8217;s two recurring patterns in modern (I hate to use the word, but&#8230;) agile businesses, that comes back across the board it&#8217;s &#8220;measure&#8221; and &#8220;iterate&#8221;. Even rudimentary tests are better than flying blind.</div>
<p />
<div>Number two, failure to recognize the worst case, generally happens when people do some kind of basic analysis. That generally amounts to taking a bunch of values and then computing the mean/median and working from there. Not recognizing the worst case is really a special case of not really assessing the distribution of your values correctly.</div>
<p />
<div>A mean is pretty interesting by itself, but you can&#8217;t get too much useful information out of it completely by itself. Knowing a service starts within a second on average is pretty useless when it has a standard deviation of a minute. (If that&#8217;s the case, descriptive statistics just showed you that your data probably doesn&#8217;t fit a normal distribution very well: the lower limit for physically possible events is at Z=-1<span style="font-family: sans-serif; font-size: 13px; line-height: 19px;">/60, unless your servers start up in negative amounts of time&#8230;</span>)</div>
<p />
<div>First of all, that service might have things that are waiting on it to get started. This is the weakest link argument: your slowest step just became a defining factor for the performance of the entire process.&nbsp;Secondly, people perceive jittery things worse than consistent things, all other things being equal. Imagine if Google loaded a lot faster often (would you even really notice?) but about as often as it would load faster, it would take five seconds.</div>
<p />
<div>Even when you have people who do some pretty reasonable statistical analysis on individual parts, that becomes only half the story in a distributed system. Even with measurements from real deployments, it&#8217;s extremely hard to predict how these things will behave.</div>
<p />
<div>Bottom line? Statistics is hard, and it&#8217;s easy to get fooled into thinking you&#8217;ve got it right even when you&#8217;re miles off (I&#8217;ve been bitten by this myself, more than once). Once you&#8217;ve done that, set up a sandboxed miniature model for your entire (distributed) system, and check the assumptions from your statistics against it. After that, you&#8217;re only likely to miss scale issues.&nbsp;</div>
<p />
<div>Even when you take all of that into account, you will get things wrong. That was my original point about cautious deployment: as long as you have that and it works, you&#8217;re allowed to get it wrong once in a while. Fail gracefully. It&#8217;s not so scary to leap the chasm when there&#8217;s a net to catch you.</div>
]]></content>
  </entry>
  
</feed>
